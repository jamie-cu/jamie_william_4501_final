{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "from typing import List\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine, Column, Integer, Float, String, Date, DateTime, MetaData, Table\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TAXI_URL: str = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "## Location Section\n",
    "shapefile_path = 'taxi_zones.shp'\n",
    "zones_gdf = gpd.read_file(shapefile_path)\n",
    "if zones_gdf.crs is None:\n",
    "    zones_gdf.set_crs(epsg=2263, inplace=True)  # Example: NY State Plane (EPSG:2263)\n",
    "zones_gdf = zones_gdf.to_crs(epsg=4326) # Reproject to WGS84 (Latitude/Longitude)\n",
    "# Calculate centroids for each zone (polygon)\n",
    "zones_gdf['centroid'] = zones_gdf.geometry.centroid\n",
    "zones_gdf['latitude'] = zones_gdf['centroid'].y\n",
    "zones_gdf['longitude'] = zones_gdf['centroid'].x\n",
    "# Retain only relevant columns: location ID, latitude, and longitude\n",
    "zones_df = zones_gdf[['LocationID', 'latitude', 'longitude']]\n",
    "# Restrict the area\n",
    "LAT_MIN, LAT_MAX = 40.560445, 40.908524\n",
    "LON_MIN, LON_MAX = -74.242330, -73.717047\n",
    "\n",
    "DATABASE_URL = \"sqlite:///transport_weather.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading: programmatically download the Yellow Taxi & High-Volume For-Hire Vehicle (HVFHV) trip data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_html() -> str:\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "    return html\n",
    "\n",
    "def find_taxi_parquet_links() -> List[str]:\n",
    "    html = get_taxi_html()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    HVFHV_a_tags = soup.find_all(\"a\", attrs={\"title\": \"High Volume For-Hire Vehicle Trip Records\"})\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    all_a_tags = HVFHV_a_tags + yellow_a_tags\n",
    "    return [a[\"href\"] for a in all_a_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use regex to filter desired datasets\n",
    "def filter_urls(urls: str, start_year:int, start_month:int, end_year:int, end_month:int) -> List[str]:\n",
    "    filtered_urls = []\n",
    "    for url in urls:\n",
    "        match = re.search(r'(\\d{4})-(\\d{2})', url)\n",
    "        if match:\n",
    "            year, month = int(match.group(1)), int(match.group(2))\n",
    "            if (start_year < year < end_year) or (year == start_year and month >= start_month) or (year == end_year and month <= end_month):\n",
    "                filtered_urls.append(url.strip())\n",
    "    return filtered_urls\n",
    "\n",
    "# Filtering URLs from January 2020 to August 2024\n",
    "urls = find_taxi_parquet_links()\n",
    "filtered_urls = filter_urls(urls, 2020, 1, 2024, 8)\n",
    "\n",
    "urls = sorted(filtered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the downloaded files. Create the directory if it doesn't exist\n",
    "output_directory = \"Dataset/\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to download a file\n",
    "def download_parquet_file(i, url:str, output_directory:str) -> None:\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "        \n",
    "        # Extract file name from the URL\n",
    "        file_name = url.split(\"/\")[-1]\n",
    "        file_path = os.path.join(output_directory, file_name)\n",
    "        \n",
    "        # Save the file\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"File {i} Downloaded: {file_name}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"File {i} Failed to download {url}. Error: {e}\")\n",
    "\n",
    "# Download all files\n",
    "for i, url in enumerate(urls):\n",
    "    download_parquet_file(i, url, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"Dataset/\"\n",
    "output_directory_yellow = 'Dataset/yellow_tripdata/'\n",
    "output_directory_uber = 'Dataset/fhvhv_tripdata/'\n",
    "os.makedirs(output_directory_yellow, exist_ok=True)\n",
    "os.makedirs(output_directory_uber, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(output_directory):\n",
    "    file_path = os.path.join(output_directory, file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        if file_name.startswith('yellow_tripdata') and file_name.endswith('.parquet'):\n",
    "            shutil.move(file_path, os.path.join(output_directory_yellow, file_name))\n",
    "        elif file_name.startswith('fhvhv_tripdata') and file_name.endswith('.parquet'):\n",
    "            shutil.move(file_path, os.path.join(output_directory_uber, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population:int, p=0.5, e=0.05, confidence=0.95) -> int:\n",
    "    # Z-score for the given confidence level\n",
    "    Z = {\n",
    "        0.90: 1.645,\n",
    "        0.95: 1.96,\n",
    "        0.99: 2.576\n",
    "    }.get(confidence, 1.96)  # Default to 95% confidence if not specified\n",
    "    \n",
    "    # Step 1: Cochran's formula for infinite population\n",
    "    n0 = (Z**2 * p * (1 - p)) / (e**2)\n",
    "    \n",
    "    # Step 2: Adjust for finite population\n",
    "    n = n0 / (1 + (n0 - 1) / population)\n",
    "    \n",
    "    return math.ceil(n)\n",
    "\n",
    "def calculate_stable_sample_size(monthly_populations: List[int], p=0.5, e=0.05, confidence=0.99, method='max') -> int:\n",
    "    \n",
    "    sample_sizes = [calculate_sample_size(N, p, e, confidence) for N in monthly_populations]\n",
    "    \n",
    "    if method == 'max':\n",
    "        return max(sample_sizes)\n",
    "    elif method == 'average':\n",
    "        return math.ceil(sum(sample_sizes) / len(sample_sizes))\n",
    "    elif method == 'safety':\n",
    "        return math.ceil(max(sample_sizes) * 1.1)  # Add a 10% safety margin\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'max', 'average', or 'safety'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi Stable sample size: 664\n"
     ]
    }
   ],
   "source": [
    "## Yellow Taxi\n",
    "yellow_file_folder = output_directory_yellow\n",
    "yellow_file_names = [f for f in os.listdir(yellow_file_folder) if os.path.isfile(os.path.join(yellow_file_folder, f))]\n",
    "\n",
    "monthly_populations_yellow = []\n",
    "for file in yellow_file_names:\n",
    "    parquet_file = pq.ParquetFile(yellow_file_folder + file)\n",
    "    monthly_populations_yellow.append(parquet_file.metadata.num_rows)\n",
    "    \n",
    "# Example monthly population sizes\n",
    "stable_size_yellow = calculate_stable_sample_size(monthly_populations_yellow, method='average')\n",
    "print(f\"Yellow Taxi Stable sample size: {stable_size_yellow}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uber Stable sample size: 664\n"
     ]
    }
   ],
   "source": [
    "## Uber\n",
    "fhvhv_file_folder = output_directory_uber\n",
    "fhvhv_file_names = [f for f in os.listdir(fhvhv_file_folder) if os.path.isfile(os.path.join(fhvhv_file_folder, f))]\n",
    "\n",
    "monthly_populations_uber = []\n",
    "for file in fhvhv_file_names:\n",
    "    parquet_file = pq.ParquetFile(fhvhv_file_folder + file)\n",
    "    monthly_populations_uber.append(parquet_file.metadata.num_rows)\n",
    "    \n",
    "# Example monthly population sizes\n",
    "stable_size_uber = calculate_stable_sample_size(monthly_populations_uber, method='average')\n",
    "print(f\"Uber Stable sample size: {stable_size_uber}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_yellow = \"Clean_Sampled_Dataset/Yellow/\"\n",
    "os.makedirs(output_directory_yellow, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_month(file:str) -> None:\n",
    "    trips_df = pd.read_parquet(yellow_file_folder + file)\n",
    "    print('Current Processing:', file)\n",
    "\n",
    "    # Merge trip data with zone centroids for pickups and dropoffs\n",
    "    trips_with_pickup = trips_df.merge(\n",
    "        zones_df,\n",
    "        how='left',\n",
    "        left_on='PULocationID',\n",
    "        right_on='LocationID'\n",
    "    ).rename(columns={'latitude': 'pickup_latitude', 'longitude': 'pickup_longitude'})\n",
    "\n",
    "    trips_with_locations = trips_with_pickup.merge(\n",
    "        zones_df,\n",
    "        how='left',\n",
    "        left_on='DOLocationID',\n",
    "        right_on='LocationID',\n",
    "        suffixes=('', '_dropoff')\n",
    "    ).rename(columns={'latitude': 'dropoff_latitude', 'longitude': 'dropoff_longitude'})\n",
    "\n",
    "    # Filter out trips with invalid location IDs\n",
    "    valid_trips = trips_with_locations.dropna(subset=['pickup_latitude', 'dropoff_latitude'])\n",
    "    valid_trips = valid_trips[\n",
    "        (valid_trips['pickup_latitude'].between(LAT_MIN, LAT_MAX)) &\n",
    "        (valid_trips['pickup_longitude'].between(LON_MIN, LON_MAX)) &\n",
    "        (valid_trips['dropoff_latitude'].between(LAT_MIN, LAT_MAX)) &\n",
    "        (valid_trips['dropoff_longitude'].between(LON_MIN, LON_MAX))\n",
    "    ]\n",
    "    ## Delete original locationID columns\n",
    "    valid_trips.drop(['PULocationID','DOLocationID','LocationID','LocationID_dropoff'],axis=1,inplace=True)\n",
    "    \n",
    "    valid_trips.columns = valid_trips.columns.str.lower()\n",
    "    \n",
    "    ## Delete records that trip_distance is missing or trip_distance <= 0, and convert datatype into Float\n",
    "    valid_trips = valid_trips.dropna(subset=['trip_distance'])\n",
    "    valid_trips = valid_trips[valid_trips['trip_distance']>0]\n",
    "    valid_trips['trip_distance'] = valid_trips['trip_distance'].astype(float)\n",
    "    \n",
    "    ## Delete records that passenger_count is missing or passenger_count <= 0, and convert datatype into Integer\n",
    "    valid_trips = valid_trips.dropna(subset=['passenger_count'])\n",
    "    valid_trips = valid_trips[valid_trips['passenger_count']>0]\n",
    "    valid_trips['passenger_count'] = valid_trips['passenger_count'].astype(int)\n",
    "    \n",
    "    ## Delete records that where Fare_amount, Total_amount, or Tolls_amount are negative.\n",
    "    valid_trips = valid_trips[\n",
    "        (valid_trips['fare_amount']>=0) &\n",
    "        (valid_trips['total_amount']>=0) &\n",
    "        (valid_trips['tolls_amount']>=0)\n",
    "        ]\n",
    "    \n",
    "    ## Delete records that Payment_type not in the valid range (1-6), and convert datatype into Integer\n",
    "    valid_trips['payment_type'] = valid_trips['payment_type'].astype(int)\n",
    "    valid_trips = valid_trips[valid_trips['payment_type'].between(1,6)]\n",
    "    \n",
    "    ## Delete records that RateCodeID not in the valid range (1-6), and convert datatype into Integer\n",
    "    valid_trips['ratecodeid'] = valid_trips['ratecodeid'].astype(int)\n",
    "    valid_trips = valid_trips[valid_trips['ratecodeid'].between(1,6)]\n",
    "    valid_trips = valid_trips.rename(columns={'ratecodeid':'RateCodeID',})\n",
    "    \n",
    "    ## Convert store_and_fwd_flag into 0 and 1\n",
    "    valid_trips['store_and_fwd_flag'] = valid_trips['store_and_fwd_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    \n",
    "    ## Convert airport_fee into Float\n",
    "    valid_trips['airport_fee'] = pd.to_numeric(valid_trips['airport_fee'], errors='coerce').fillna(0)\n",
    "    \n",
    "    ## Rename: extra -> Miscellaneous_Extras, tpep_pickup_datetime → pickup_datetime, tpep_dropoff_datetime → dropoff_datetime\n",
    "    valid_trips = valid_trips.rename(\n",
    "        columns={'extra':'Miscellaneous_Extras','tpep_pickup_datetime':'pickup_datetime','tpep_dropoff_datetime':'dropoff_datetime'})\n",
    "    \n",
    "    ## Delete records that dropoff_datetime is earlier than pickup_datetime.\n",
    "    valid_trips = valid_trips[valid_trips['dropoff_datetime'] >= valid_trips['pickup_datetime']]\n",
    "    \n",
    "    ## Sampling & Save to parquet file\n",
    "    valid_trips = valid_trips.sample(n=stable_size_yellow, random_state=42).reset_index(drop=True)\n",
    "    valid_trips.to_parquet(output_directory_yellow + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(yellow_file_names[:]):\n",
    "    get_and_clean_taxi_month(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_sampled_records = pd.DataFrame()\n",
    "yellow_sampled_file_names = [f for f in os.listdir(output_directory_yellow) if os.path.isfile(os.path.join(output_directory_yellow, f))]\n",
    "\n",
    "for file in yellow_sampled_file_names:\n",
    "    sampled_df = pd.read_parquet(output_directory_yellow + file)\n",
    "    yellow_sampled_records = pd.concat([yellow_sampled_records,sampled_df],axis=0)\n",
    "    \n",
    "output_directory_final = \"Clean_Sampled_Dataset/Final/\"\n",
    "os.makedirs(output_directory_final, exist_ok=True)\n",
    "yellow_sampled_records.to_parquet(output_directory_final + 'Yellow_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>Miscellaneous_Extras</th>\n",
       "      <th>...</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-25 15:18:34</td>\n",
       "      <td>2020-01-25 15:24:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.732579</td>\n",
       "      <td>-73.994305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31 22:47:15</td>\n",
       "      <td>2020-01-31 23:09:04</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>26.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.729506</td>\n",
       "      <td>-73.949540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-12 10:43:53</td>\n",
       "      <td>2020-01-12 10:51:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.717773</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>40.734576</td>\n",
       "      <td>-74.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23 17:35:31</td>\n",
       "      <td>2020-01-23 17:41:18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-09 17:16:48</td>\n",
       "      <td>2020-01-09 17:45:01</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.85</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>-73.992438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorid     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0         1 2020-01-25 15:18:34 2020-01-25 15:24:03                1   \n",
       "1         1 2020-01-31 22:47:15 2020-01-31 23:09:04                1   \n",
       "2         1 2020-01-12 10:43:53 2020-01-12 10:51:52                1   \n",
       "3         2 2020-01-23 17:35:31 2020-01-23 17:41:18                1   \n",
       "4         1 2020-01-09 17:16:48 2020-01-09 17:45:01                2   \n",
       "\n",
       "   trip_distance  RateCodeID  store_and_fwd_flag  payment_type  fare_amount  \\\n",
       "0           0.60           1                   0             1          5.0   \n",
       "1           4.00           1                   0             1         18.5   \n",
       "2           1.40           1                   0             1          7.5   \n",
       "3           1.05           1                   0             1          6.0   \n",
       "4           2.70           1                   0             1         18.0   \n",
       "\n",
       "   Miscellaneous_Extras  ...  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0                   2.5  ...        1.00           0.0                    0.3   \n",
       "1                   3.0  ...        4.45           0.0                    0.3   \n",
       "2                   2.5  ...        2.15           0.0                    0.3   \n",
       "3                   1.0  ...        2.06           0.0                    0.3   \n",
       "4                   3.5  ...        5.55           0.0                    0.3   \n",
       "\n",
       "   total_amount  congestion_surcharge  airport_fee  pickup_latitude  \\\n",
       "0          9.30                   2.5          0.0        40.740337   \n",
       "1         26.75                   2.5          0.0        40.727620   \n",
       "2         12.95                   2.5          0.0        40.717773   \n",
       "3         12.36                   2.5          0.0        40.765484   \n",
       "4         27.85                   2.5          0.0        40.780436   \n",
       "\n",
       "   pickup_longitude  dropoff_latitude  dropoff_longitude  \n",
       "0        -73.990458         40.732579         -73.994305  \n",
       "1        -73.985937         40.729506         -73.949540  \n",
       "2        -74.007880         40.734576         -74.002875  \n",
       "3        -73.954739         40.780436         -73.957012  \n",
       "4        -73.957012         40.748497         -73.992438  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data = yellow_sampled_records\n",
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37184 entries, 0 to 663\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   vendorid               37184 non-null  int64         \n",
      " 1   pickup_datetime        37184 non-null  datetime64[us]\n",
      " 2   dropoff_datetime       37184 non-null  datetime64[us]\n",
      " 3   passenger_count        37184 non-null  int64         \n",
      " 4   trip_distance          37184 non-null  float64       \n",
      " 5   RateCodeID             37184 non-null  int64         \n",
      " 6   store_and_fwd_flag     37184 non-null  int64         \n",
      " 7   payment_type           37184 non-null  int64         \n",
      " 8   fare_amount            37184 non-null  float64       \n",
      " 9   Miscellaneous_Extras   37184 non-null  float64       \n",
      " 10  mta_tax                37184 non-null  float64       \n",
      " 11  tip_amount             37184 non-null  float64       \n",
      " 12  tolls_amount           37184 non-null  float64       \n",
      " 13  improvement_surcharge  37184 non-null  float64       \n",
      " 14  total_amount           37184 non-null  float64       \n",
      " 15  congestion_surcharge   37184 non-null  float64       \n",
      " 16  airport_fee            37184 non-null  float64       \n",
      " 17  pickup_latitude        37184 non-null  float64       \n",
      " 18  pickup_longitude       37184 non-null  float64       \n",
      " 19  dropoff_latitude       37184 non-null  float64       \n",
      " 20  dropoff_longitude      37184 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(14), int64(5)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>Miscellaneous_Extras</th>\n",
       "      <th>...</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184</td>\n",
       "      <td>37184</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.00000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.727221</td>\n",
       "      <td>2022-05-02 00:15:05.196455</td>\n",
       "      <td>2022-05-02 00:31:09.242389</td>\n",
       "      <td>1.429674</td>\n",
       "      <td>3.14086</td>\n",
       "      <td>1.039937</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>1.229857</td>\n",
       "      <td>14.919423</td>\n",
       "      <td>1.231025</td>\n",
       "      <td>...</td>\n",
       "      <td>2.765244</td>\n",
       "      <td>0.409460</td>\n",
       "      <td>0.553679</td>\n",
       "      <td>22.136030</td>\n",
       "      <td>2.326404</td>\n",
       "      <td>0.082347</td>\n",
       "      <td>40.753944</td>\n",
       "      <td>-73.967747</td>\n",
       "      <td>40.755782</td>\n",
       "      <td>-73.971609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-01-01 00:46:20</td>\n",
       "      <td>2020-01-01 00:49:27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.592023</td>\n",
       "      <td>-74.071771</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-03-01 06:07:27.500000</td>\n",
       "      <td>2021-03-01 06:14:43.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.06000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740439</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2022-05-01 00:20:16</td>\n",
       "      <td>2022-05-01 00:48:41.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.78000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2023-06-30 22:56:06.500000</td>\n",
       "      <td>2023-06-30 23:00:25.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.16000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2024-08-31 23:04:44</td>\n",
       "      <td>2024-08-31 23:26:45</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>47.96000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>224.100000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>40.877138</td>\n",
       "      <td>-73.735554</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.445394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>3.97191</td>\n",
       "      <td>0.254993</td>\n",
       "      <td>0.095324</td>\n",
       "      <td>0.452647</td>\n",
       "      <td>13.447006</td>\n",
       "      <td>1.496043</td>\n",
       "      <td>...</td>\n",
       "      <td>3.442572</td>\n",
       "      <td>1.735434</td>\n",
       "      <td>0.336562</td>\n",
       "      <td>17.365268</td>\n",
       "      <td>0.635504</td>\n",
       "      <td>0.345755</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.044121</td>\n",
       "      <td>0.031729</td>\n",
       "      <td>0.035067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendorid             pickup_datetime            dropoff_datetime  \\\n",
       "count  37184.000000                       37184                       37184   \n",
       "mean       1.727221  2022-05-02 00:15:05.196455  2022-05-02 00:31:09.242389   \n",
       "min        1.000000         2020-01-01 00:46:20         2020-01-01 00:49:27   \n",
       "25%        1.000000  2021-03-01 06:07:27.500000  2021-03-01 06:14:43.500000   \n",
       "50%        2.000000         2022-05-01 00:20:16  2022-05-01 00:48:41.500000   \n",
       "75%        2.000000  2023-06-30 22:56:06.500000  2023-06-30 23:00:25.750000   \n",
       "max        2.000000         2024-08-31 23:04:44         2024-08-31 23:26:45   \n",
       "std        0.445394                         NaN                         NaN   \n",
       "\n",
       "       passenger_count  trip_distance    RateCodeID  store_and_fwd_flag  \\\n",
       "count     37184.000000    37184.00000  37184.000000        37184.000000   \n",
       "mean          1.429674        3.14086      1.039937            0.009171   \n",
       "min           1.000000        0.01000      1.000000            0.000000   \n",
       "25%           1.000000        1.06000      1.000000            0.000000   \n",
       "50%           1.000000        1.78000      1.000000            0.000000   \n",
       "75%           1.000000        3.16000      1.000000            0.000000   \n",
       "max           7.000000       47.96000      5.000000            1.000000   \n",
       "std           0.971560        3.97191      0.254993            0.095324   \n",
       "\n",
       "       payment_type   fare_amount  Miscellaneous_Extras  ...    tip_amount  \\\n",
       "count  37184.000000  37184.000000          37184.000000  ...  37184.000000   \n",
       "mean       1.229857     14.919423              1.231025  ...      2.765244   \n",
       "min        1.000000      0.000000              0.000000  ...      0.000000   \n",
       "25%        1.000000      7.200000              0.000000  ...      0.020000   \n",
       "50%        1.000000     10.500000              0.500000  ...      2.190000   \n",
       "75%        1.000000     16.500000              2.500000  ...      3.500000   \n",
       "max        4.000000    159.000000             11.750000  ...    208.000000   \n",
       "std        0.452647     13.447006              1.496043  ...      3.442572   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  37184.000000           37184.000000  37184.000000   \n",
       "mean       0.409460               0.553679     22.136030   \n",
       "min        0.000000               0.000000      0.000000   \n",
       "25%        0.000000               0.300000     12.360000   \n",
       "50%        0.000000               0.300000     16.560000   \n",
       "75%        0.000000               1.000000     23.800000   \n",
       "max       36.000000               1.000000    224.100000   \n",
       "std        1.735434               0.336562     17.365268   \n",
       "\n",
       "       congestion_surcharge   airport_fee  pickup_latitude  pickup_longitude  \\\n",
       "count          37184.000000  37184.000000     37184.000000      37184.000000   \n",
       "mean               2.326404      0.082347        40.753944        -73.967747   \n",
       "min                0.000000      0.000000        40.592023        -74.071771   \n",
       "25%                2.500000      0.000000        40.740439        -73.989845   \n",
       "50%                2.500000      0.000000        40.758028        -73.977698   \n",
       "75%                2.500000      0.000000        40.773633        -73.965146   \n",
       "max                2.500000      1.750000        40.877138        -73.735554   \n",
       "std                0.635504      0.345755         0.030316          0.044121   \n",
       "\n",
       "       dropoff_latitude  dropoff_longitude  \n",
       "count      37184.000000       37184.000000  \n",
       "mean          40.755782         -73.971609  \n",
       "min           40.576961         -74.174000  \n",
       "25%           40.740337         -73.989845  \n",
       "50%           40.758028         -73.977698  \n",
       "75%           40.775932         -73.959635  \n",
       "max           40.899529         -73.726655  \n",
       "std            0.031729           0.035067  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_uber = \"Clean_Sampled_Dataset/Uber/\"\n",
    "os.makedirs(output_directory_uber, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(file:str) -> None:\n",
    "    trips_df = pd.read_parquet(fhvhv_file_folder + file)\n",
    "    print('Current Processing:', file)\n",
    "    \n",
    "    ## Retain records that are Uber rides\n",
    "    trips_df = trips_df[trips_df['hvfhs_license_num'] == 'HV0003']\n",
    "\n",
    "    # Merge trip data with zone centroids for pickups and dropoffs\n",
    "    trips_with_pickup = trips_df.merge(\n",
    "        zones_df,\n",
    "        how='left',\n",
    "        left_on='PULocationID',\n",
    "        right_on='LocationID'\n",
    "    ).rename(columns={'latitude': 'pickup_latitude', 'longitude': 'pickup_longitude'})\n",
    "\n",
    "    trips_with_locations = trips_with_pickup.merge(\n",
    "        zones_df,\n",
    "        how='left',\n",
    "        left_on='DOLocationID',\n",
    "        right_on='LocationID',\n",
    "        suffixes=('', '_dropoff')\n",
    "    ).rename(columns={'latitude': 'dropoff_latitude', 'longitude': 'dropoff_longitude'})\n",
    "\n",
    "    # Filter out trips with invalid location IDs\n",
    "    valid_trips = trips_with_locations.dropna(subset=['pickup_latitude', 'dropoff_latitude'])\n",
    "\n",
    "    # Delete records that start_pos or end_pos is out of range\n",
    "    LAT_MIN, LAT_MAX = 40.560445, 40.908524\n",
    "    LON_MIN, LON_MAX = -74.242330, -73.717047\n",
    "    \n",
    "    valid_trips = valid_trips[\n",
    "        (valid_trips['pickup_latitude'].between(LAT_MIN, LAT_MAX)) &\n",
    "        (valid_trips['pickup_longitude'].between(LON_MIN, LON_MAX)) &\n",
    "        (valid_trips['dropoff_latitude'].between(LAT_MIN, LAT_MAX)) &\n",
    "        (valid_trips['dropoff_longitude'].between(LON_MIN, LON_MAX))\n",
    "    ]\n",
    "    ## Delete original locationID columns\n",
    "    valid_trips.drop(['PULocationID','DOLocationID','LocationID','LocationID_dropoff'],axis=1,inplace=True)\n",
    "    \n",
    "    valid_trips.columns = valid_trips.columns.str.lower()\n",
    "    \n",
    "    ## Delete records that trip_distance is missing or trip_distance <= 0, and convert datatype into Float\n",
    "    valid_trips = valid_trips.dropna(subset=['trip_miles'])\n",
    "    valid_trips = valid_trips[valid_trips['trip_miles']>0]\n",
    "    valid_trips['trip_miles'] = valid_trips['trip_miles'].astype(float)\n",
    "    \n",
    "    ## Delete records that trip_time is missing or trip_distance <= 0, and convert datatype into Float\n",
    "    valid_trips = valid_trips.dropna(subset=['trip_time'])\n",
    "    valid_trips = valid_trips[valid_trips['trip_time']>0]\n",
    "    valid_trips['trip_time'] = valid_trips['trip_time'].astype(float)\n",
    "    \n",
    "    ## Delete records that where base_passenger_fare, tolls, sales_tax, bcf, tips, congestion_surcharge or driver_pay are negative.\n",
    "    valid_trips = valid_trips[\n",
    "        (valid_trips['base_passenger_fare']>=0) &\n",
    "        (valid_trips['tolls']>=0) &\n",
    "        (valid_trips['sales_tax']>=0) &\n",
    "        (valid_trips['bcf']>=0) &\n",
    "        (valid_trips['tips']>=0) &\n",
    "        (valid_trips['congestion_surcharge']>=0) &\n",
    "        (valid_trips['driver_pay']>=0) \n",
    "        ]\n",
    "    \n",
    "    ## Convert shared_request_flag, shared_match_flag, access_a_ride_flag, wav_request_flag, wav_match_flag into 0 and 1\n",
    "    valid_trips['shared_request_flag'] = valid_trips['shared_request_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    valid_trips['shared_match_flag'] = valid_trips['shared_match_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    valid_trips['access_a_ride_flag'] = valid_trips['access_a_ride_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    valid_trips['wav_request_flag'] = valid_trips['wav_request_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    valid_trips['wav_match_flag'] = valid_trips['wav_match_flag'].map({'Y':1,'N':0}).fillna(0)\n",
    "    \n",
    "    ## Delete records that dropoff_datetime is earlier than pickup_datetime.\n",
    "    valid_trips = valid_trips[valid_trips['dropoff_datetime'] >= valid_trips['pickup_datetime']]\n",
    "    \n",
    "    ## Delete records that on_scene_datetime is earlier than request_datetime.\n",
    "    valid_trips = valid_trips[valid_trips['on_scene_datetime'] >= valid_trips['request_datetime']]\n",
    "    \n",
    "    ## Rename: bcf -> Black_Car_Fund\n",
    "    valid_trips = valid_trips.rename(\n",
    "        columns={'bcf':'Black_Car_Fund',})\n",
    "    \n",
    "    ## Delete useless columns: dispatching_base_num, Hvfhs_license_num, originating_base_num\n",
    "    valid_trips = valid_trips.drop(['hvfhs_license_num','dispatching_base_num','originating_base_num'], axis=1)\n",
    "    \n",
    "    ## Sampling & Save to parquet file\n",
    "    valid_trips = valid_trips.sample(n=stable_size_uber, random_state=42).reset_index(drop=True)\n",
    "    valid_trips.to_parquet(output_directory_uber + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(fhvhv_file_names[:]):\n",
    "    get_and_clean_uber_month(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_sampled_records = pd.DataFrame()\n",
    "uber_sampled_file_names = [f for f in os.listdir(output_directory_uber) if os.path.isfile(os.path.join(output_directory_uber, f))]\n",
    "\n",
    "for file in uber_sampled_file_names:\n",
    "    sampled_df = pd.read_parquet(output_directory_uber + file)\n",
    "    uber_sampled_records = pd.concat([uber_sampled_records,sampled_df],axis=0)\n",
    "    \n",
    "output_directory_final = \"Clean_Sampled_Dataset/Final/\"\n",
    "os.makedirs(output_directory_final, exist_ok=True)\n",
    "uber_sampled_records.to_parquet(output_directory_final + 'Uber_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>Black_Car_Fund</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-11 18:47:52</td>\n",
       "      <td>2020-01-11 18:49:25</td>\n",
       "      <td>2020-01-11 18:50:40</td>\n",
       "      <td>2020-01-11 18:58:32</td>\n",
       "      <td>1.26</td>\n",
       "      <td>472.0</td>\n",
       "      <td>8.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.77</td>\n",
       "      <td>...</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.601429</td>\n",
       "      <td>-73.983537</td>\n",
       "      <td>40.601429</td>\n",
       "      <td>-73.983537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-31 15:01:20</td>\n",
       "      <td>2020-01-31 15:01:29</td>\n",
       "      <td>2020-01-31 15:02:42</td>\n",
       "      <td>2020-01-31 15:13:28</td>\n",
       "      <td>2.14</td>\n",
       "      <td>646.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.760314</td>\n",
       "      <td>-73.941997</td>\n",
       "      <td>40.771570</td>\n",
       "      <td>-73.928333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06 11:32:29</td>\n",
       "      <td>2020-01-06 11:35:08</td>\n",
       "      <td>2020-01-06 11:35:58</td>\n",
       "      <td>2020-01-06 11:56:02</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>13.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.757312</td>\n",
       "      <td>-73.885317</td>\n",
       "      <td>40.737699</td>\n",
       "      <td>-73.924673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-19 20:39:28</td>\n",
       "      <td>2020-01-19 20:40:20</td>\n",
       "      <td>2020-01-19 20:42:46</td>\n",
       "      <td>2020-01-19 20:53:33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>647.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>7.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.706527</td>\n",
       "      <td>-73.901709</td>\n",
       "      <td>40.694994</td>\n",
       "      <td>-73.922240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22 05:01:59</td>\n",
       "      <td>2020-01-22 05:03:35</td>\n",
       "      <td>2020-01-22 05:05:49</td>\n",
       "      <td>2020-01-22 05:14:41</td>\n",
       "      <td>2.06</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.626273</td>\n",
       "      <td>-73.930097</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2020-01-11 18:47:52 2020-01-11 18:49:25 2020-01-11 18:50:40   \n",
       "1 2020-01-31 15:01:20 2020-01-31 15:01:29 2020-01-31 15:02:42   \n",
       "2 2020-01-06 11:32:29 2020-01-06 11:35:08 2020-01-06 11:35:58   \n",
       "3 2020-01-19 20:39:28 2020-01-19 20:40:20 2020-01-19 20:42:46   \n",
       "4 2020-01-22 05:01:59 2020-01-22 05:03:35 2020-01-22 05:05:49   \n",
       "\n",
       "     dropoff_datetime  trip_miles  trip_time  base_passenger_fare  tolls  \\\n",
       "0 2020-01-11 18:58:32        1.26      472.0                 8.63    0.0   \n",
       "1 2020-01-31 15:13:28        2.14      646.0                 4.73    0.0   \n",
       "2 2020-01-06 11:56:02        3.61     1204.0                 8.98    0.0   \n",
       "3 2020-01-19 20:53:33        2.33      647.0                 8.83    0.0   \n",
       "4 2020-01-22 05:14:41        2.06      532.0                 9.65    0.0   \n",
       "\n",
       "   Black_Car_Fund  sales_tax  ...  driver_pay  shared_request_flag  \\\n",
       "0            0.22       0.77  ...        5.39                    0   \n",
       "1            0.12       0.42  ...        7.67                    0   \n",
       "2            0.22       0.80  ...       13.88                    1   \n",
       "3            0.22       0.78  ...        7.89                    0   \n",
       "4            0.24       0.86  ...        6.64                    0   \n",
       "\n",
       "   shared_match_flag  access_a_ride_flag  wav_request_flag  wav_match_flag  \\\n",
       "0                  0                 0.0                 0               0   \n",
       "1                  0                 0.0                 0               0   \n",
       "2                  0                 0.0                 0               0   \n",
       "3                  0                 0.0                 0               0   \n",
       "4                  0                 0.0                 0               0   \n",
       "\n",
       "   pickup_latitude  pickup_longitude  dropoff_latitude  dropoff_longitude  \n",
       "0        40.601429        -73.983537         40.601429         -73.983537  \n",
       "1        40.760314        -73.941997         40.771570         -73.928333  \n",
       "2        40.757312        -73.885317         40.737699         -73.924673  \n",
       "3        40.706527        -73.901709         40.694994         -73.922240  \n",
       "4        40.626273        -73.930097         40.620924         -73.956825  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data = uber_sampled_records\n",
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37184 entries, 0 to 663\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   request_datetime      37184 non-null  datetime64[us]\n",
      " 1   on_scene_datetime     37184 non-null  datetime64[us]\n",
      " 2   pickup_datetime       37184 non-null  datetime64[us]\n",
      " 3   dropoff_datetime      37184 non-null  datetime64[us]\n",
      " 4   trip_miles            37184 non-null  float64       \n",
      " 5   trip_time             37184 non-null  float64       \n",
      " 6   base_passenger_fare   37184 non-null  float64       \n",
      " 7   tolls                 37184 non-null  float64       \n",
      " 8   Black_Car_Fund        37184 non-null  float64       \n",
      " 9   sales_tax             37184 non-null  float64       \n",
      " 10  congestion_surcharge  37184 non-null  float64       \n",
      " 11  airport_fee           27280 non-null  float64       \n",
      " 12  tips                  37184 non-null  float64       \n",
      " 13  driver_pay            37184 non-null  float64       \n",
      " 14  shared_request_flag   37184 non-null  int64         \n",
      " 15  shared_match_flag     37184 non-null  int64         \n",
      " 16  access_a_ride_flag    37184 non-null  float64       \n",
      " 17  wav_request_flag      37184 non-null  int64         \n",
      " 18  wav_match_flag        37184 non-null  int64         \n",
      " 19  pickup_latitude       37184 non-null  float64       \n",
      " 20  pickup_longitude      37184 non-null  float64       \n",
      " 21  dropoff_latitude      37184 non-null  float64       \n",
      " 22  dropoff_longitude     37184 non-null  float64       \n",
      "dtypes: datetime64[us](4), float64(15), int64(4)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>Black_Car_Fund</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37184</td>\n",
       "      <td>37184</td>\n",
       "      <td>37184</td>\n",
       "      <td>37184</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "      <td>37184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-01 23:55:11.932820</td>\n",
       "      <td>2022-05-01 23:58:53.492389</td>\n",
       "      <td>2022-05-01 23:59:59.119352</td>\n",
       "      <td>2022-05-02 00:17:43.175855</td>\n",
       "      <td>4.360401</td>\n",
       "      <td>1063.879787</td>\n",
       "      <td>20.921077</td>\n",
       "      <td>0.634296</td>\n",
       "      <td>0.612010</td>\n",
       "      <td>1.877993</td>\n",
       "      <td>...</td>\n",
       "      <td>16.814301</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.064732</td>\n",
       "      <td>40.737384</td>\n",
       "      <td>-73.934362</td>\n",
       "      <td>40.737447</td>\n",
       "      <td>-73.934261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:23:24</td>\n",
       "      <td>2020-01-01 00:25:57</td>\n",
       "      <td>2020-01-01 00:29:47</td>\n",
       "      <td>2020-01-01 00:38:28</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.186419</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.186419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-28 23:45:55.500000</td>\n",
       "      <td>2021-02-28 23:47:05</td>\n",
       "      <td>2021-02-28 23:47:20.750000</td>\n",
       "      <td>2021-02-28 23:53:25.750000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.691507</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>-73.984052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-30 23:47:52.500000</td>\n",
       "      <td>2022-04-30 23:51:57.500000</td>\n",
       "      <td>2022-04-30 23:53:14</td>\n",
       "      <td>2022-05-01 00:03:40</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>16.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.737699</td>\n",
       "      <td>-73.948789</td>\n",
       "      <td>40.739496</td>\n",
       "      <td>-73.947442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-01 00:11:25.500000</td>\n",
       "      <td>2023-07-01 00:14:47.500000</td>\n",
       "      <td>2023-07-01 00:14:59.750000</td>\n",
       "      <td>2023-07-01 00:35:35.750000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>1371.000000</td>\n",
       "      <td>26.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.774376</td>\n",
       "      <td>-73.899536</td>\n",
       "      <td>40.774376</td>\n",
       "      <td>-73.895620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 20:56:10</td>\n",
       "      <td>2024-08-31 21:00:51</td>\n",
       "      <td>2024-08-31 21:02:52</td>\n",
       "      <td>2024-08-31 21:27:55</td>\n",
       "      <td>78.870000</td>\n",
       "      <td>8822.000000</td>\n",
       "      <td>259.090000</td>\n",
       "      <td>45.140000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>24.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.270252</td>\n",
       "      <td>723.080127</td>\n",
       "      <td>15.120357</td>\n",
       "      <td>2.428773</td>\n",
       "      <td>0.485812</td>\n",
       "      <td>1.418026</td>\n",
       "      <td>...</td>\n",
       "      <td>12.084181</td>\n",
       "      <td>0.146066</td>\n",
       "      <td>0.090343</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>0.068482</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>0.068916</td>\n",
       "      <td>0.067372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime           on_scene_datetime  \\\n",
       "count                       37184                       37184   \n",
       "mean   2022-05-01 23:55:11.932820  2022-05-01 23:58:53.492389   \n",
       "min           2020-01-01 00:23:24         2020-01-01 00:25:57   \n",
       "25%    2021-02-28 23:45:55.500000         2021-02-28 23:47:05   \n",
       "50%    2022-04-30 23:47:52.500000  2022-04-30 23:51:57.500000   \n",
       "75%    2023-07-01 00:11:25.500000  2023-07-01 00:14:47.500000   \n",
       "max           2024-08-31 20:56:10         2024-08-31 21:00:51   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                  pickup_datetime            dropoff_datetime    trip_miles  \\\n",
       "count                       37184                       37184  37184.000000   \n",
       "mean   2022-05-01 23:59:59.119352  2022-05-02 00:17:43.175855      4.360401   \n",
       "min           2020-01-01 00:29:47         2020-01-01 00:38:28      0.020000   \n",
       "25%    2021-02-28 23:47:20.750000  2021-02-28 23:53:25.750000      1.540000   \n",
       "50%           2022-04-30 23:53:14         2022-05-01 00:03:40      2.790000   \n",
       "75%    2023-07-01 00:14:59.750000  2023-07-01 00:35:35.750000      5.560000   \n",
       "max           2024-08-31 21:02:52         2024-08-31 21:27:55     78.870000   \n",
       "std                           NaN                         NaN      4.270252   \n",
       "\n",
       "          trip_time  base_passenger_fare         tolls  Black_Car_Fund  \\\n",
       "count  37184.000000         37184.000000  37184.000000    37184.000000   \n",
       "mean    1063.879787            20.921077      0.634296        0.612010   \n",
       "min       23.000000             0.000000      0.000000        0.000000   \n",
       "25%      557.000000            10.550000      0.000000        0.290000   \n",
       "50%      878.000000            16.520000      0.000000        0.470000   \n",
       "75%     1371.000000            26.330000      0.000000        0.770000   \n",
       "max     8822.000000           259.090000     45.140000        8.200000   \n",
       "std      723.080127            15.120357      2.428773        0.485812   \n",
       "\n",
       "          sales_tax  ...    driver_pay  shared_request_flag  \\\n",
       "count  37184.000000  ...  37184.000000         37184.000000   \n",
       "mean       1.877993  ...     16.814301             0.021810   \n",
       "min        0.000000  ...      0.000000             0.000000   \n",
       "25%        0.920000  ...      8.270000             0.000000   \n",
       "50%        1.450000  ...     13.280000             0.000000   \n",
       "75%        2.370000  ...     21.560000             0.000000   \n",
       "max       24.260000  ...    176.150000             1.000000   \n",
       "std        1.418026  ...     12.084181             0.146066   \n",
       "\n",
       "       shared_match_flag  access_a_ride_flag  wav_request_flag  \\\n",
       "count       37184.000000        37184.000000      37184.000000   \n",
       "mean            0.008229            0.000215          0.001694   \n",
       "min             0.000000            0.000000          0.000000   \n",
       "25%             0.000000            0.000000          0.000000   \n",
       "50%             0.000000            0.000000          0.000000   \n",
       "75%             0.000000            0.000000          0.000000   \n",
       "max             1.000000            1.000000          1.000000   \n",
       "std             0.090343            0.014666          0.041127   \n",
       "\n",
       "       wav_match_flag  pickup_latitude  pickup_longitude  dropoff_latitude  \\\n",
       "count    37184.000000     37184.000000      37184.000000      37184.000000   \n",
       "mean         0.064732        40.737384        -73.934362         40.737447   \n",
       "min          0.000000        40.561994        -74.186419         40.561994   \n",
       "25%          0.000000        40.691507        -73.984196         40.690787   \n",
       "50%          0.000000        40.737699        -73.948789         40.739496   \n",
       "75%          0.000000        40.774376        -73.899536         40.774376   \n",
       "max          1.000000        40.899529        -73.726655         40.899529   \n",
       "std          0.246056         0.068482          0.065073          0.068916   \n",
       "\n",
       "       dropoff_longitude  \n",
       "count       37184.000000  \n",
       "mean          -73.934261  \n",
       "min           -74.186419  \n",
       "25%           -73.984052  \n",
       "50%           -73.947442  \n",
       "75%           -73.895620  \n",
       "max           -73.726655  \n",
       "std             0.067372  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Weather Data: Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_file_folder = 'Dataset/weather_data/'\n",
    "weather_data_files = ['2020_weather.csv','2021_weather.csv','2022_weather.csv','2023_weather.csv','2024_weather.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Processing: 2020_weather.csv\n",
      "Current Processing: 2021_weather.csv\n",
      "Current Processing: 2022_weather.csv\n",
      "Current Processing: 2023_weather.csv\n",
      "Current Processing: 2024_weather.csv\n"
     ]
    }
   ],
   "source": [
    "weather_data_hourly_df = pd.DataFrame()\n",
    "for file in weather_data_files:\n",
    "    print(\"Current Processing:\", file)\n",
    "    weather_data = pd.read_csv(weather_data_file_folder + file)\n",
    "\n",
    "    ## Split Date and Hour\n",
    "    weather_data[['Date', 'Hour']] = weather_data['DATE'].str.split('T', expand=True)\n",
    "    \n",
    "    weather_data_hourly = weather_data[weather_data['Hour'] !='23:59:00']\n",
    "    weather_data_hourly['Hour'] = weather_data_hourly['Hour'].str.split(':').str[0]\n",
    "    weather_data_hourly = weather_data_hourly.groupby(['Date','Hour']).first().reset_index()\n",
    "\n",
    "    original_columns = list(weather_data_hourly.columns)\n",
    "    columns_to_drop = ['DATE','ELEVATION','STATION','NAME','LATITUDE','LONGITUDE','NormalsCoolingDegreeDay','NormalsHeatingDegreeDay','Sunrise', 'Sunset','WindEquipmentChangeDate'] \\\n",
    "    + ['AWND','CDSD','CLDD','DSNW','HDSD','HTDD','DYTS','DYHF',] \\\n",
    "    + ['HourlyPresentWeatherType','HourlySkyConditions','REM','HourlyWindDirection'] \\\n",
    "    + [col for col in original_columns if col.startswith('Daily')] \\\n",
    "    + [col for col in original_columns if col.startswith('Monthly')] \\\n",
    "    + [col for col in original_columns if col.startswith('Backup')] \\\n",
    "    + [col for col in original_columns if col.startswith('ShortDuration')]\n",
    "    weather_data_hourly = weather_data_hourly.drop(columns_to_drop,axis=1)\n",
    "\n",
    "    ## Transform data type & Fill missing values\n",
    "    weather_data_hourly['Hour'] = weather_data_hourly['Hour'].astype(int)\n",
    "    weather_data_hourly['HourlyAltimeterSetting'] = pd.to_numeric(weather_data_hourly['HourlyAltimeterSetting'], errors='coerce')\n",
    "    weather_data_hourly['HourlyAltimeterSetting'] = weather_data_hourly['HourlyAltimeterSetting'].fillna(weather_data_hourly['HourlyAltimeterSetting'].mean())\n",
    "    weather_data_hourly['HourlyDewPointTemperature'] = pd.to_numeric(weather_data_hourly['HourlyDewPointTemperature'], errors='coerce')\n",
    "    weather_data_hourly['HourlyDewPointTemperature'] = weather_data_hourly['HourlyDewPointTemperature'].fillna(weather_data_hourly['HourlyDewPointTemperature'].mean())\n",
    "    weather_data_hourly['HourlyDryBulbTemperature'] = pd.to_numeric(weather_data_hourly['HourlyDryBulbTemperature'], errors='coerce')\n",
    "    weather_data_hourly['HourlyDryBulbTemperature'] = weather_data_hourly['HourlyDryBulbTemperature'].fillna(weather_data_hourly['HourlyDryBulbTemperature'].mean())\n",
    "    weather_data_hourly['HourlySeaLevelPressure'] = pd.to_numeric(weather_data_hourly['HourlySeaLevelPressure'], errors='coerce')\n",
    "    weather_data_hourly['HourlySeaLevelPressure'] = weather_data_hourly['HourlySeaLevelPressure'].fillna(weather_data_hourly['HourlySeaLevelPressure'].mean())\n",
    "    weather_data_hourly['HourlyStationPressure'] = pd.to_numeric(weather_data_hourly['HourlyStationPressure'], errors='coerce')\n",
    "    weather_data_hourly['HourlyStationPressure'] = weather_data_hourly['HourlyStationPressure'].fillna(weather_data_hourly['HourlyStationPressure'].mean())\n",
    "\n",
    "    weather_data_hourly['HourlyVisibility'] = weather_data_hourly['HourlyVisibility'].str.extract(r'(\\d+\\.\\d+)', expand=False)\n",
    "    weather_data_hourly['HourlyVisibility'] = pd.to_numeric(weather_data_hourly['HourlyVisibility'], errors='coerce')\n",
    "    weather_data_hourly['HourlyVisibility'] = weather_data_hourly['HourlyVisibility'].fillna(weather_data_hourly['HourlyVisibility'].mean())\n",
    "\n",
    "    weather_data_hourly['HourlyPrecipitation'] = weather_data_hourly['HourlyPrecipitation'].replace('T', 0.0005)\n",
    "    weather_data_hourly['HourlyPrecipitation'] = weather_data_hourly['HourlyPrecipitation'].replace(['M', ''], np.nan)\n",
    "    weather_data_hourly['HourlyPrecipitation'] = weather_data_hourly['HourlyPrecipitation'].fillna(0)\n",
    "    weather_data_hourly['HourlyPrecipitation'] = pd.to_numeric(weather_data_hourly['HourlyPrecipitation'], errors='coerce')\n",
    "    weather_data_hourly['HourlyPrecipitation'] = weather_data_hourly['HourlyPrecipitation'].fillna(0)\n",
    "\n",
    "    weather_data_hourly['HourlyPressureChange'] = pd.to_numeric(weather_data_hourly['HourlyPressureChange'], errors='coerce')\n",
    "    weather_data_hourly['HourlyPressureChange'] = weather_data_hourly['HourlyPressureChange'].fillna(0)\n",
    "    weather_data_hourly['HourlyPressureTendency'] = pd.to_numeric(weather_data_hourly['HourlyPressureTendency'], errors='coerce')\n",
    "    weather_data_hourly['HourlyPressureTendency'] = weather_data_hourly['HourlyPressureTendency'].fillna(0)\n",
    "    weather_data_hourly['HourlyRelativeHumidity'] = pd.to_numeric(weather_data_hourly['HourlyPrecipitation'], errors='coerce')\n",
    "    weather_data_hourly['HourlyRelativeHumidity'] = weather_data_hourly['HourlyRelativeHumidity'].fillna(0)\n",
    "    weather_data_hourly['HourlyWetBulbTemperature'] = pd.to_numeric(weather_data_hourly['HourlyWetBulbTemperature'], errors='coerce')\n",
    "    weather_data_hourly['HourlyWetBulbTemperature'] = weather_data_hourly['HourlyWetBulbTemperature'].fillna(weather_data_hourly['HourlyWetBulbTemperature'].mean())\n",
    "    weather_data_hourly['HourlyWindGustSpeed'] = weather_data_hourly['HourlyWindGustSpeed'].fillna(weather_data_hourly['HourlyWindGustSpeed'].mean())\n",
    "    weather_data_hourly['HourlyWindSpeed'] = weather_data_hourly['HourlyWindSpeed'].fillna(weather_data_hourly['HourlyWindSpeed'].mean())\n",
    "\n",
    "    weather_data_hourly_df = pd.concat([weather_data_hourly_df,weather_data_hourly],axis=0)\n",
    "    \n",
    "weather_data_hourly_df['Date'] = pd.to_datetime(weather_data_hourly_df['Date'])\n",
    "    \n",
    "output_directory_final = \"Clean_Sampled_Dataset/Final/\"\n",
    "os.makedirs(output_directory_final, exist_ok=True)\n",
    "weather_data_hourly_df.to_parquet(output_directory_final + 'Weather_hourly.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>HourlyPressureTendency</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlySeaLevelPressure</th>\n",
       "      <th>HourlyStationPressure</th>\n",
       "      <th>HourlyVisibility</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>29.66</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.64</td>\n",
       "      <td>29.49</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.300203</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>29.67</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.65</td>\n",
       "      <td>29.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>29.68</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.66</td>\n",
       "      <td>29.51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>29.70</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>29.70</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Hour REPORT_TYPE  SOURCE  HourlyAltimeterSetting  \\\n",
       "0 2020-01-01     0       FM-15       7                   29.66   \n",
       "1 2020-01-01     1       FM-15       7                   29.67   \n",
       "2 2020-01-01     2       FM-15       7                   29.68   \n",
       "3 2020-01-01     3       FM-15       7                   29.70   \n",
       "4 2020-01-01     4       FM-15       7                   29.70   \n",
       "\n",
       "   HourlyDewPointTemperature  HourlyDryBulbTemperature  HourlyPrecipitation  \\\n",
       "0                       26.0                      40.0                  0.0   \n",
       "1                       27.0                      39.0                  0.0   \n",
       "2                       26.0                      39.0                  0.0   \n",
       "3                       24.0                      39.0                  0.0   \n",
       "4                       23.0                      38.0                  0.0   \n",
       "\n",
       "   HourlyPressureChange  HourlyPressureTendency  HourlyRelativeHumidity  \\\n",
       "0                 -0.01                     3.0                     0.0   \n",
       "1                  0.00                     0.0                     0.0   \n",
       "2                  0.00                     0.0                     0.0   \n",
       "3                 -0.03                     3.0                     0.0   \n",
       "4                  0.00                     0.0                     0.0   \n",
       "\n",
       "   HourlySeaLevelPressure  HourlyStationPressure  HourlyVisibility  \\\n",
       "0                   29.64                  29.49              10.0   \n",
       "1                   29.65                  29.50              10.0   \n",
       "2                   29.66                  29.51              10.0   \n",
       "3                   29.67                  29.53              10.0   \n",
       "4                   29.67                  29.53              10.0   \n",
       "\n",
       "   HourlyWetBulbTemperature  HourlyWindGustSpeed  HourlyWindSpeed  \n",
       "0                      35.0            21.300203              8.0  \n",
       "1                      34.0            17.000000              8.0  \n",
       "2                      34.0            23.000000             14.0  \n",
       "3                      33.0            23.000000             11.0  \n",
       "4                      32.0            20.000000              6.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data = weather_data_hourly_df\n",
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42143 entries, 0 to 7086\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Date                       42143 non-null  datetime64[ns]\n",
      " 1   Hour                       42143 non-null  int64         \n",
      " 2   REPORT_TYPE                42143 non-null  object        \n",
      " 3   SOURCE                     42143 non-null  int64         \n",
      " 4   HourlyAltimeterSetting     42143 non-null  float64       \n",
      " 5   HourlyDewPointTemperature  42143 non-null  float64       \n",
      " 6   HourlyDryBulbTemperature   42143 non-null  float64       \n",
      " 7   HourlyPrecipitation        42143 non-null  float64       \n",
      " 8   HourlyPressureChange       42143 non-null  float64       \n",
      " 9   HourlyPressureTendency     42143 non-null  float64       \n",
      " 10  HourlyRelativeHumidity     42143 non-null  float64       \n",
      " 11  HourlySeaLevelPressure     42143 non-null  float64       \n",
      " 12  HourlyStationPressure      42143 non-null  float64       \n",
      " 13  HourlyVisibility           42143 non-null  float64       \n",
      " 14  HourlyWetBulbTemperature   42143 non-null  float64       \n",
      " 15  HourlyWindGustSpeed        42143 non-null  float64       \n",
      " 16  HourlyWindSpeed            42143 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(13), int64(2), object(1)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>HourlyPressureTendency</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlySeaLevelPressure</th>\n",
       "      <th>HourlyStationPressure</th>\n",
       "      <th>HourlyVisibility</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42143</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "      <td>42143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-27 14:51:45.142016512</td>\n",
       "      <td>11.497425</td>\n",
       "      <td>6.957407</td>\n",
       "      <td>30.042690</td>\n",
       "      <td>42.868218</td>\n",
       "      <td>57.421804</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>1.423202</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>30.015235</td>\n",
       "      <td>29.872520</td>\n",
       "      <td>9.082238</td>\n",
       "      <td>50.506325</td>\n",
       "      <td>21.291719</td>\n",
       "      <td>5.100049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.860000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>28.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-14 12:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.870000</td>\n",
       "      <td>29.730000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>20.551695</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-28 00:00:00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>30.040000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>29.870000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>21.300203</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-10 00:00:00</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>30.190000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.160000</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>21.475073</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-22 00:00:00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>30.740000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.922439</td>\n",
       "      <td>0.249271</td>\n",
       "      <td>0.225974</td>\n",
       "      <td>18.606820</td>\n",
       "      <td>16.499179</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>2.582359</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.226635</td>\n",
       "      <td>0.225671</td>\n",
       "      <td>2.190958</td>\n",
       "      <td>15.150230</td>\n",
       "      <td>1.866752</td>\n",
       "      <td>15.778008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date          Hour        SOURCE  \\\n",
       "count                          42143  42143.000000  42143.000000   \n",
       "mean   2022-05-27 14:51:45.142016512     11.497425      6.957407   \n",
       "min              2020-01-01 00:00:00      0.000000      4.000000   \n",
       "25%              2021-03-14 12:00:00      5.000000      7.000000   \n",
       "50%              2022-05-28 00:00:00     11.000000      7.000000   \n",
       "75%              2023-08-10 00:00:00     17.000000      7.000000   \n",
       "max              2024-10-22 00:00:00     23.000000      7.000000   \n",
       "std                              NaN      6.922439      0.249271   \n",
       "\n",
       "       HourlyAltimeterSetting  HourlyDewPointTemperature  \\\n",
       "count            42143.000000               42143.000000   \n",
       "mean                30.042690                  42.868218   \n",
       "min                 28.860000                 -15.000000   \n",
       "25%                 29.900000                  28.000000   \n",
       "50%                 30.040000                  44.000000   \n",
       "75%                 30.190000                  59.000000   \n",
       "max                 30.760000                  80.000000   \n",
       "std                  0.225974                  18.606820   \n",
       "\n",
       "       HourlyDryBulbTemperature  HourlyPrecipitation  HourlyPressureChange  \\\n",
       "count              42143.000000         42143.000000          42143.000000   \n",
       "mean                  57.421804             0.002872             -0.000168   \n",
       "min                    4.000000             0.000000             -0.310000   \n",
       "25%                   44.000000             0.000000              0.000000   \n",
       "50%                   58.000000             0.000000              0.000000   \n",
       "75%                   71.000000             0.000000              0.000000   \n",
       "max                   97.000000             1.600000              0.320000   \n",
       "std                   16.499179             0.022523              0.026283   \n",
       "\n",
       "       HourlyPressureTendency  HourlyRelativeHumidity  HourlySeaLevelPressure  \\\n",
       "count            42143.000000            42143.000000            42143.000000   \n",
       "mean                 1.423202                0.002872               30.015235   \n",
       "min                  0.000000                0.000000               28.840000   \n",
       "25%                  0.000000                0.000000               29.870000   \n",
       "50%                  0.000000                0.000000               30.010000   \n",
       "75%                  1.000000                0.000000               30.160000   \n",
       "max                  9.000000                1.600000               30.740000   \n",
       "std                  2.582359                0.022523                0.226635   \n",
       "\n",
       "       HourlyStationPressure  HourlyVisibility  HourlyWetBulbTemperature  \\\n",
       "count           42143.000000      42143.000000              42143.000000   \n",
       "mean               29.872520          9.082238                 50.506325   \n",
       "min                28.690000          0.000000                  2.000000   \n",
       "25%                29.730000         10.000000                 38.000000   \n",
       "50%                29.870000         10.000000                 51.000000   \n",
       "75%                30.020000         10.000000                 64.000000   \n",
       "max                30.590000         10.000000                 81.000000   \n",
       "std                 0.225671          2.190958                 15.150230   \n",
       "\n",
       "       HourlyWindGustSpeed  HourlyWindSpeed  \n",
       "count         42143.000000     42143.000000  \n",
       "mean             21.291719         5.100049  \n",
       "min              16.000000         0.000000  \n",
       "25%              20.551695         3.000000  \n",
       "50%              21.300203         5.000000  \n",
       "75%              21.475073         7.000000  \n",
       "max              51.000000      2237.000000  \n",
       "std               1.866752        15.778008  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Weather Data: Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Processing: 2020_weather.csv\n",
      "Current Processing: 2021_weather.csv\n",
      "Current Processing: 2022_weather.csv\n",
      "Current Processing: 2023_weather.csv\n",
      "Current Processing: 2024_weather.csv\n"
     ]
    }
   ],
   "source": [
    "weather_data_daily_df = pd.DataFrame()\n",
    "for file in weather_data_files:\n",
    "    print(\"Current Processing:\", file)\n",
    "    weather_data = pd.read_csv(weather_data_file_folder + file)\n",
    "\n",
    "    ## Split Date and Hour\n",
    "    weather_data[['Date', 'Hour']] = weather_data['DATE'].str.split('T', expand=True)\n",
    "\n",
    "    weather_data_daily = weather_data[weather_data['Hour'] =='23:59:00']\n",
    "    weather_data_daily['Hour'] = weather_data_daily['Hour'].str.split(':').str[0]\n",
    "    weather_data_daily = weather_data_daily[weather_data_daily['REPORT_TYPE'] == 'SOD  ']\n",
    "    weather_data_daily = weather_data_daily[['Date','Hour'] + [col for col in list(weather_data_daily.columns) if col not in ['Date','Hour']]]\n",
    "\n",
    "    original_columns = list(weather_data_daily.columns)\n",
    "    columns_to_drop = ['DATE','ELEVATION','Hour','STATION','NAME','LATITUDE','LONGITUDE','WindEquipmentChangeDate','DailyWeather'] \\\n",
    "        + ['AWND','CDSD','CLDD','DSNW','HDSD','HTDD','DYTS','DYHF',] \\\n",
    "        + ['HourlyPresentWeatherType','HourlySkyConditions','REM','NormalsCoolingDegreeDay','DailyPeakWindDirection','NormalsHeatingDegreeDay','DailySustainedWindDirection'] \\\n",
    "        + [col for col in original_columns if col.startswith('Hourly')] \\\n",
    "        + [col for col in original_columns if col.startswith('Monthly')] \\\n",
    "        + [col for col in original_columns if col.startswith('Backup')] \\\n",
    "        + [col for col in original_columns if col.startswith('ShortDuration')]\n",
    "    weather_data_daily = weather_data_daily.drop(columns_to_drop,axis=1)\n",
    "\n",
    "    special_treat_col1 = ['DailySnowfall','DailyPrecipitation','DailySnowDepth']\n",
    "    for col in special_treat_col1:\n",
    "        weather_data_daily[col] = weather_data_daily[col].replace('T', 0.0005)\n",
    "        weather_data_daily[col] = weather_data_daily[col].replace(['M', ''], np.nan)\n",
    "        weather_data_daily[col] = weather_data_daily[col].fillna(0)\n",
    "        weather_data_daily[col] = pd.to_numeric(weather_data_daily[col], errors='coerce')\n",
    "        weather_data_daily[col] = weather_data_daily[col].fillna(0)\n",
    "        \n",
    "    special_treat_col2 = ['DailyAverageDewPointTemperature','DailyAverageDryBulbTemperature','DailyAverageRelativeHumidity','DailyAverageSeaLevelPressure',\n",
    "    'DailyAverageStationPressure','DailyAverageWetBulbTemperature','DailyAverageWindSpeed',\n",
    "    'DailyCoolingDegreeDays',\n",
    "    'DailyDepartureFromNormalAverageTemperature',\n",
    "    'DailyHeatingDegreeDays',\n",
    "    'DailyCoolingDegreeDays',\n",
    "    'DailyMaximumDryBulbTemperature',\n",
    "    'DailyMinimumDryBulbTemperature',\n",
    "    'DailySustainedWindSpeed',\n",
    "    'DailyPeakWindSpeed',\n",
    "    ]\n",
    "    for col in special_treat_col2:\n",
    "        weather_data_daily[col] = pd.to_numeric(weather_data_daily[col], errors='coerce')\n",
    "        weather_data_daily[col] = weather_data_daily[col].fillna(weather_data_daily[col].mean())\n",
    "\n",
    "    weather_data_daily_df = pd.concat([weather_data_daily_df,weather_data_daily])\n",
    "\n",
    "weather_data_daily_df['Date'] = pd.to_datetime(weather_data_daily_df['Date'])\n",
    "\n",
    "sunrise_data_daily_df = weather_data_daily_df[['Date','Sunrise']]\n",
    "sunrise_data_daily_df['Sunrise'] = sunrise_data_daily_df['Sunrise'].astype(int)\n",
    "sunset_data_daily_df = weather_data_daily_df[['Date','Sunset']]\n",
    "sunset_data_daily_df['Sunset'] = sunset_data_daily_df['Sunset'].astype(int)\n",
    "    \n",
    "output_directory_final = \"Clean_Sampled_Dataset/Final/\"\n",
    "os.makedirs(output_directory_final, exist_ok=True)\n",
    "weather_data_daily_df.to_parquet(output_directory_final + 'Weather_daily.parquet')\n",
    "sunrise_data_daily_df.to_parquet(output_directory_final + 'Sunrise_daily.parquet')\n",
    "sunset_data_daily_df.to_parquet(output_directory_final + 'Sunset_daily.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>DailyAverageDewPointTemperature</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>DailyAverageRelativeHumidity</th>\n",
       "      <th>DailyAverageSeaLevelPressure</th>\n",
       "      <th>DailyAverageStationPressure</th>\n",
       "      <th>...</th>\n",
       "      <th>DailyCoolingDegreeDays</th>\n",
       "      <th>DailyDepartureFromNormalAverageTemperature</th>\n",
       "      <th>DailyHeatingDegreeDays</th>\n",
       "      <th>DailyMaximumDryBulbTemperature</th>\n",
       "      <th>DailyMinimumDryBulbTemperature</th>\n",
       "      <th>DailyPeakWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailySnowDepth</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DailySustainedWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>29.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>29.81</td>\n",
       "      <td>29.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>29.62</td>\n",
       "      <td>29.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>SOD</td>\n",
       "      <td>6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date REPORT_TYPE  SOURCE  Sunrise  Sunset  \\\n",
       "24  2020-01-01       SOD         6    720.0  1639.0   \n",
       "49  2020-01-02       SOD         6    720.0  1640.0   \n",
       "86  2020-01-03       SOD         6    720.0  1641.0   \n",
       "144 2020-01-04       SOD         6    720.0  1642.0   \n",
       "169 2020-01-05       SOD         6    720.0  1643.0   \n",
       "\n",
       "     DailyAverageDewPointTemperature  DailyAverageDryBulbTemperature  \\\n",
       "24                              21.0                            38.0   \n",
       "49                              25.0                            41.0   \n",
       "86                              41.0                            47.0   \n",
       "144                             45.0                            46.0   \n",
       "169                             20.0                            39.0   \n",
       "\n",
       "     DailyAverageRelativeHumidity  DailyAverageSeaLevelPressure  \\\n",
       "24                           52.0                         29.76   \n",
       "49                           52.0                         29.91   \n",
       "86                           82.0                         29.81   \n",
       "144                          90.0                         29.62   \n",
       "169                          48.0                         29.84   \n",
       "\n",
       "     DailyAverageStationPressure  ...  DailyCoolingDegreeDays  \\\n",
       "24                         29.62  ...                     0.0   \n",
       "49                         29.77  ...                     0.0   \n",
       "86                         29.67  ...                     0.0   \n",
       "144                        29.49  ...                     0.0   \n",
       "169                        29.69  ...                     0.0   \n",
       "\n",
       "     DailyDepartureFromNormalAverageTemperature  DailyHeatingDegreeDays  \\\n",
       "24                                          4.6                    27.0   \n",
       "49                                          7.7                    24.0   \n",
       "86                                         13.9                    18.0   \n",
       "144                                        13.0                    19.0   \n",
       "169                                         6.1                    26.0   \n",
       "\n",
       "     DailyMaximumDryBulbTemperature  DailyMinimumDryBulbTemperature  \\\n",
       "24                             41.0                            34.0   \n",
       "49                             49.0                            33.0   \n",
       "86                             49.0                            44.0   \n",
       "144                            51.0                            41.0   \n",
       "169                            42.0                            35.0   \n",
       "\n",
       "     DailyPeakWindSpeed  DailyPrecipitation  DailySnowDepth  DailySnowfall  \\\n",
       "24                 29.0              0.0000             0.0            0.0   \n",
       "49                 22.0              0.0000             0.0            0.0   \n",
       "86                 15.0              0.1500             0.0            0.0   \n",
       "144                24.0              0.2700             0.0            0.0   \n",
       "169                43.0              0.0005             0.0            0.0   \n",
       "\n",
       "     DailySustainedWindSpeed  \n",
       "24                      17.0  \n",
       "49                      13.0  \n",
       "86                      10.0  \n",
       "144                     15.0  \n",
       "169                     25.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data = weather_data_daily_df\n",
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1755 entries, 24 to 9387\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                      Non-Null Count  Dtype         \n",
      "---  ------                                      --------------  -----         \n",
      " 0   Date                                        1755 non-null   datetime64[ns]\n",
      " 1   REPORT_TYPE                                 1755 non-null   object        \n",
      " 2   SOURCE                                      1755 non-null   int64         \n",
      " 3   Sunrise                                     1755 non-null   float64       \n",
      " 4   Sunset                                      1755 non-null   float64       \n",
      " 5   DailyAverageDewPointTemperature             1755 non-null   float64       \n",
      " 6   DailyAverageDryBulbTemperature              1755 non-null   float64       \n",
      " 7   DailyAverageRelativeHumidity                1755 non-null   float64       \n",
      " 8   DailyAverageSeaLevelPressure                1755 non-null   float64       \n",
      " 9   DailyAverageStationPressure                 1755 non-null   float64       \n",
      " 10  DailyAverageWetBulbTemperature              1755 non-null   float64       \n",
      " 11  DailyAverageWindSpeed                       1755 non-null   float64       \n",
      " 12  DailyCoolingDegreeDays                      1755 non-null   float64       \n",
      " 13  DailyDepartureFromNormalAverageTemperature  1755 non-null   float64       \n",
      " 14  DailyHeatingDegreeDays                      1755 non-null   float64       \n",
      " 15  DailyMaximumDryBulbTemperature              1755 non-null   float64       \n",
      " 16  DailyMinimumDryBulbTemperature              1755 non-null   float64       \n",
      " 17  DailyPeakWindSpeed                          1755 non-null   float64       \n",
      " 18  DailyPrecipitation                          1755 non-null   float64       \n",
      " 19  DailySnowDepth                              1755 non-null   float64       \n",
      " 20  DailySnowfall                               1755 non-null   float64       \n",
      " 21  DailySustainedWindSpeed                     1755 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(19), int64(1), object(1)\n",
      "memory usage: 315.4+ KB\n"
     ]
    }
   ],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>DailyAverageDewPointTemperature</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>DailyAverageRelativeHumidity</th>\n",
       "      <th>DailyAverageSeaLevelPressure</th>\n",
       "      <th>DailyAverageStationPressure</th>\n",
       "      <th>DailyAverageWetBulbTemperature</th>\n",
       "      <th>...</th>\n",
       "      <th>DailyCoolingDegreeDays</th>\n",
       "      <th>DailyDepartureFromNormalAverageTemperature</th>\n",
       "      <th>DailyHeatingDegreeDays</th>\n",
       "      <th>DailyMaximumDryBulbTemperature</th>\n",
       "      <th>DailyMinimumDryBulbTemperature</th>\n",
       "      <th>DailyPeakWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailySnowDepth</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DailySustainedWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1755</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-27 04:02:03.076923136</td>\n",
       "      <td>6.0</td>\n",
       "      <td>559.546439</td>\n",
       "      <td>1789.639316</td>\n",
       "      <td>42.547550</td>\n",
       "      <td>58.009117</td>\n",
       "      <td>60.986410</td>\n",
       "      <td>30.008397</td>\n",
       "      <td>29.867609</td>\n",
       "      <td>50.223058</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773789</td>\n",
       "      <td>2.552821</td>\n",
       "      <td>10.764672</td>\n",
       "      <td>64.811966</td>\n",
       "      <td>50.719658</td>\n",
       "      <td>93.742962</td>\n",
       "      <td>0.142020</td>\n",
       "      <td>0.154419</td>\n",
       "      <td>0.039105</td>\n",
       "      <td>80.984980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.220000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-24.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-14 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>29.890000</td>\n",
       "      <td>29.730000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-27 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>1809.000000</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>60.455399</td>\n",
       "      <td>29.990000</td>\n",
       "      <td>29.860000</td>\n",
       "      <td>49.699531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.639456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-08 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>643.500000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>30.140000</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-21 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>30.660000</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>2237.000000</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.696961</td>\n",
       "      <td>104.053733</td>\n",
       "      <td>17.553825</td>\n",
       "      <td>16.083056</td>\n",
       "      <td>15.142271</td>\n",
       "      <td>0.206158</td>\n",
       "      <td>0.214240</td>\n",
       "      <td>14.462464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.848973</td>\n",
       "      <td>6.841136</td>\n",
       "      <td>11.964977</td>\n",
       "      <td>16.956312</td>\n",
       "      <td>15.595589</td>\n",
       "      <td>389.424618</td>\n",
       "      <td>0.414555</td>\n",
       "      <td>1.041103</td>\n",
       "      <td>0.493456</td>\n",
       "      <td>380.591538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date  SOURCE      Sunrise       Sunset  \\\n",
       "count                           1755  1755.0  1755.000000  1755.000000   \n",
       "mean   2022-05-27 04:02:03.076923136     6.0   559.546439  1789.639316   \n",
       "min              2020-01-01 00:00:00     6.0   424.000000  1628.000000   \n",
       "25%              2021-03-14 12:00:00     6.0   451.000000  1710.000000   \n",
       "50%              2022-05-27 00:00:00     6.0   543.000000  1809.000000   \n",
       "75%              2023-08-08 12:00:00     6.0   643.500000  1904.000000   \n",
       "max              2024-10-21 00:00:00     6.0   720.000000  1931.000000   \n",
       "std                              NaN     0.0   101.696961   104.053733   \n",
       "\n",
       "       DailyAverageDewPointTemperature  DailyAverageDryBulbTemperature  \\\n",
       "count                      1755.000000                     1755.000000   \n",
       "mean                         42.547550                       58.009117   \n",
       "min                          -7.000000                       11.000000   \n",
       "25%                          29.000000                       45.000000   \n",
       "50%                          42.600000                       59.000000   \n",
       "75%                          57.000000                       72.000000   \n",
       "max                          74.000000                       88.000000   \n",
       "std                          17.553825                       16.083056   \n",
       "\n",
       "       DailyAverageRelativeHumidity  DailyAverageSeaLevelPressure  \\\n",
       "count                   1755.000000                   1755.000000   \n",
       "mean                      60.986410                     30.008397   \n",
       "min                       19.000000                     29.220000   \n",
       "25%                       50.000000                     29.890000   \n",
       "50%                       60.455399                     29.990000   \n",
       "75%                       72.000000                     30.140000   \n",
       "max                       95.000000                     30.660000   \n",
       "std                       15.142271                      0.206158   \n",
       "\n",
       "       DailyAverageStationPressure  DailyAverageWetBulbTemperature  ...  \\\n",
       "count                  1755.000000                     1755.000000  ...   \n",
       "mean                     29.867609                       50.223058  ...   \n",
       "min                      29.000000                        8.000000  ...   \n",
       "25%                      29.730000                       39.000000  ...   \n",
       "50%                      29.860000                       49.699531  ...   \n",
       "75%                      30.010000                       63.000000  ...   \n",
       "max                      30.510000                       76.000000  ...   \n",
       "std                       0.214240                       14.462464  ...   \n",
       "\n",
       "       DailyCoolingDegreeDays  DailyDepartureFromNormalAverageTemperature  \\\n",
       "count             1755.000000                                 1755.000000   \n",
       "mean                 3.773789                                    2.552821   \n",
       "min                  0.000000                                  -24.200000   \n",
       "25%                  0.000000                                   -1.900000   \n",
       "50%                  0.000000                                    2.200000   \n",
       "75%                  7.000000                                    6.900000   \n",
       "max                 23.000000                                   28.800000   \n",
       "std                  5.848973                                    6.841136   \n",
       "\n",
       "       DailyHeatingDegreeDays  DailyMaximumDryBulbTemperature  \\\n",
       "count             1755.000000                     1755.000000   \n",
       "mean                10.764672                       64.811966   \n",
       "min                  0.000000                       15.000000   \n",
       "25%                  0.000000                       51.000000   \n",
       "50%                  6.000000                       66.000000   \n",
       "75%                 20.000000                       79.000000   \n",
       "max                 54.000000                       98.000000   \n",
       "std                 11.964977                       16.956312   \n",
       "\n",
       "       DailyMinimumDryBulbTemperature  DailyPeakWindSpeed  DailyPrecipitation  \\\n",
       "count                     1755.000000         1755.000000         1755.000000   \n",
       "mean                        50.719658           93.742962            0.142020   \n",
       "min                          3.000000            9.000000            0.000000   \n",
       "25%                         38.000000           17.000000            0.000000   \n",
       "50%                         50.000000           22.000000            0.000000   \n",
       "75%                         65.000000           27.000000            0.060000   \n",
       "max                         81.000000         2237.000000            7.130000   \n",
       "std                         15.595589          389.424618            0.414555   \n",
       "\n",
       "       DailySnowDepth  DailySnowfall  DailySustainedWindSpeed  \n",
       "count     1755.000000    1755.000000              1755.000000  \n",
       "mean         0.154419       0.039105                80.984980  \n",
       "min          0.000000       0.000000                 6.000000  \n",
       "25%          0.000000       0.000000                10.000000  \n",
       "50%          0.000000       0.000000                13.639456  \n",
       "75%          0.000000       0.000000                16.000000  \n",
       "max         14.000000      14.800000              2237.000000  \n",
       "std          1.041103       0.493456               380.591538  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLite database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Uber trips table schema\n",
    "uber_trips_table = Table(\n",
    "    'uber_trips', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('request_datetime', DateTime),\n",
    "    Column('on_scene_datetime', DateTime),\n",
    "    Column('pickup_datetime', DateTime),\n",
    "    Column('dropoff_datetime', DateTime),\n",
    "    Column('trip_miles', Float),\n",
    "    Column('trip_time', Float),\n",
    "    Column('base_passenger_fare', Float),\n",
    "    Column('tolls', Float),\n",
    "    Column('Black_Car_Fund', Float),\n",
    "    Column('sales_tax', Float),\n",
    "    Column('congestion_surcharge', Float),\n",
    "    Column('airport_fee', Float),\n",
    "    Column('tips', Float),\n",
    "    Column('driver_pay', Float),\n",
    "    Column('shared_request_flag', Integer),  # Y/N\n",
    "    Column('shared_match_flag', Integer),    # Y/N\n",
    "    Column('access_a_ride_flag', Integer),   # Y/N\n",
    "    Column('wav_request_flag', Integer),     # Y/N\n",
    "    Column('wav_match_flag', Integer),       # Y/N\n",
    "    Column('pickup_latitude', Float),\n",
    "    Column('pickup_longitude', Float),\n",
    "    Column('dropoff_latitude', Float),\n",
    "    Column('dropoff_longitude', Float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Yellow Taxi trips table schema\n",
    "yellow_trips_table = Table(\n",
    "    'yellow_taxi_trips', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('vendorid', Integer),  # Can be TEXT or INTEGER depending on data\n",
    "    Column('pickup_datetime', DateTime),\n",
    "    Column('dropoff_datetime', DateTime),\n",
    "    Column('passenger_count', Integer),\n",
    "    Column('trip_distance', Float),\n",
    "    Column('RateCodeID', Integer),\n",
    "    Column('store_and_fwd_flag', Integer),  # Y/N\n",
    "    Column('payment_type', Integer),\n",
    "    Column('fare_amount', Float),\n",
    "    Column('Miscellaneous_Extras', Float),\n",
    "    Column('mta_tax', Float),\n",
    "    Column('tip_amount', Float),\n",
    "    Column('tolls_amount', Float),\n",
    "    Column('improvement_surcharge', Float),\n",
    "    Column('total_amount', Float),\n",
    "    Column('congestion_surcharge', Float),\n",
    "    Column('airport_fee', Float),\n",
    "    Column('pickup_latitude', Float),\n",
    "    Column('pickup_longitude', Float),\n",
    "    Column('dropoff_latitude', Float),\n",
    "    Column('dropoff_longitude', Float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weather hourly table schema\n",
    "weather_hourly_table = Table(\n",
    "    'weather_hourly', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('Date', Date),\n",
    "    Column('Hour', Integer),\n",
    "    Column('REPORT_TYPE', String),\n",
    "    Column('SOURCE', String),\n",
    "    Column('HourlyAltimeterSetting', Float),\n",
    "    Column('HourlyDewPointTemperature', Float),\n",
    "    Column('HourlyDryBulbTemperature', Float),\n",
    "    Column('HourlyPrecipitation', Float),\n",
    "    Column('HourlyPressureChange', Float),\n",
    "    Column('HourlyPressureTendency', String),\n",
    "    Column('HourlyRelativeHumidity', Float),\n",
    "    Column('HourlySeaLevelPressure', Float),\n",
    "    Column('HourlyStationPressure', Float),\n",
    "    Column('HourlyVisibility', Float),\n",
    "    Column('HourlyWetBulbTemperature', Float),\n",
    "    Column('HourlyWindGustSpeed', Float),\n",
    "    Column('HourlyWindSpeed', Float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weather daily table schema\n",
    "weather_daily_table = Table(\n",
    "    'weather_daily', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('Date', Date),\n",
    "    Column('REPORT_TYPE', String),\n",
    "    Column('SOURCE', String),\n",
    "    Column('Sunrise', String),\n",
    "    Column('Sunset', String),\n",
    "    Column('DailyAverageDewPointTemperature', Float),\n",
    "    Column('DailyAverageDryBulbTemperature', Float),\n",
    "    Column('DailyAverageRelativeHumidity', Float),\n",
    "    Column('DailyAverageSeaLevelPressure', Float),\n",
    "    Column('DailyAverageStationPressure', Float),\n",
    "    Column('DailyAverageWetBulbTemperature', Float),\n",
    "    Column('DailyAverageWindSpeed', Float),\n",
    "    Column('DailyCoolingDegreeDays', Float),\n",
    "    Column('DailyDepartureFromNormalAverageTemperature', Float),\n",
    "    Column('DailyHeatingDegreeDays', Float),\n",
    "    Column('DailyMaximumDryBulbTemperature', Float),\n",
    "    Column('DailyMinimumDryBulbTemperature', Float),\n",
    "    Column('DailyPeakWindSpeed', Float),\n",
    "    Column('DailyPrecipitation', Float),\n",
    "    Column('DailySnowDepth', Float),\n",
    "    Column('DailySnowfall', Float),\n",
    "    Column('DailySustainedWindSpeed', Float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sunrise daily table schema\n",
    "sunrise_daily_table = Table(\n",
    "    'sunrise_daily', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('Date', Date),\n",
    "    Column('Sunrise', Integer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sunrise daily table schema\n",
    "sunset_daily_table = Table(\n",
    "    'sunset_daily', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('Date', Date),\n",
    "    Column('Sunrise', Integer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_df = pd.read_parquet(output_directory_final + 'Yellow_all.parquet')\n",
    "yellow_df.to_sql('yellow_taxi_trips', engine, if_exists='replace', index=False)\n",
    "\n",
    "uber_df = pd.read_parquet(output_directory_final + 'Uber_all.parquet')\n",
    "uber_df.to_sql('uber_trips', engine, if_exists='replace', index=False)\n",
    "\n",
    "weather_hourly_df = pd.read_parquet(output_directory_final + 'Weather_hourly.parquet')\n",
    "weather_hourly_df.to_sql('weather_hourly', engine, if_exists='replace', index=False)\n",
    "\n",
    "weather_daily_df = pd.read_parquet(output_directory_final + 'Weather_daily.parquet')\n",
    "weather_daily_df.to_sql('weather_daily', engine, if_exists='replace', index=False)\n",
    "\n",
    "sunrise_daily_df = pd.read_parquet(output_directory_final + 'Sunrise_daily.parquet')\n",
    "sunrise_daily_df.to_sql('sunrise_daily', engine, if_exists='replace', index=False)\n",
    "\n",
    "sunset_daily_df = pd.read_parquet(output_directory_final + 'Sunset_daily.parquet')\n",
    "sunset_daily_df.to_sql('sunset_daily', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema.sql file has been successfully generated.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the SQLite database\n",
    "db_path = 'transport_weather.db' # Replace with your actual database file\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query the sqlite_master table to get schema definitions\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name, sql FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Open a file to write the schema\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as file:\n",
    "    for table_name, schema in cursor.fetchall():\n",
    "        if schema:  # Exclude views or invalid entries\n",
    "            file.write(schema + \";\\n\\n\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Schema.sql file has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db_path = 'transport_weather.db'\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What’s the most popular hour to take a taxi?\n",
    "# For 01-2020 through 08-2024, show the popularity of Yellow Taxi rides for each hour of the day. \n",
    "QUERY_1_FILENAME = \"yellow_taxi_by_hour_frequency.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "    SELECT \n",
    "        strftime('%H', pickup_datetime) AS hour,\n",
    "        COUNT(*) AS ride_cnt\n",
    "    FROM \n",
    "        yellow_taxi_trips\n",
    "    GROUP BY \n",
    "        hour\n",
    "    ORDER BY \n",
    "        ride_cnt DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_1).fetchall()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18:00 is most popular time slot, which is align with our intuition that during that time people are taking taxi/uber to go home or go out for dinner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What’s the most popular day of the week to take an Uber?\n",
    "# For the same time frame, show the popularity of Uber rides for each day of the week.\n",
    "QUERY_2_FILENAME = \"uber_by_day_of_week_frequency.sql\"\n",
    "\n",
    "QUERY_2 = '''\n",
    "    SELECT \n",
    "        strftime('%w', pickup_datetime) AS day_of_week,\n",
    "        COUNT(*) AS ride_cnt\n",
    "    FROM \n",
    "        uber_trips\n",
    "    GROUP BY \n",
    "        day_of_week\n",
    "    ORDER BY \n",
    "        ride_cnt DESC;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_2).fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekday 6 and 5 are Sunday and Saturday and they're most popular time slot which is align with our intuition that people hang out during these days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: What’s the 95% percentile of trip distance in January 2024?\n",
    "# What is the 95% percentile of distance traveled for all hired rides trips during January 2024?  \n",
    "\n",
    "# The result should be a float. It’s okay if it’s a single float within a list and/or tuple, or a result within a dataframe.\n",
    "QUERY_3_FILENAME = \"travel_distance_Jan2024_95_percent_percentile.sql\"\n",
    "\n",
    "QUERY_3 ='''\n",
    "WITH total AS \n",
    "(\n",
    "    SELECT \n",
    "        trip_distance\n",
    "    FROM \n",
    "        yellow_taxi_trips\n",
    "    WHERE \n",
    "        strftime('%Y-%m', pickup_datetime) = '2024-01'\n",
    "UNION ALL\n",
    "\n",
    "    SELECT \n",
    "        trip_miles AS trip_distance\n",
    "    FROM \n",
    "        uber_trips\n",
    "    WHERE \n",
    "        strftime('%Y-%m', pickup_datetime) = '2024-01'\n",
    "),\n",
    "ordered_total AS\n",
    "(\n",
    "    SELECT\n",
    "        trip_distance,\n",
    "        ROW_NUMBER()OVER(ORDER BY trip_distance) AS row_num,\n",
    "        COUNT(*) OVER() AS total_cnt\n",
    "    FROM\n",
    "        total\n",
    "),\n",
    "percentile AS\n",
    "(\n",
    "    SELECT\n",
    "        trip_distance\n",
    "    FROM\n",
    "        ordered_total\n",
    "    WHERE\n",
    "        row_num >= FLOOR(total_cnt*0.95) AND row_num <= CEIL(total_cnt*0.95)\n",
    ")\n",
    "    SELECT\n",
    "        trip_distance\n",
    "    FROM\n",
    "        percentile\n",
    "    ORDER BY trip_distance\n",
    "    LIMIT 1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_3).fetchall()\n",
    "results[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 4: What was the weather like for the busiest days in 2023?\n",
    "What were the top 10 days with the highest number of all hired rides for 2023, and for each day, what was the average distance, average precipitation amount, and average wind speed.\n",
    "\n",
    "The result should be a list of 10 tuples (or a dataframe of 10 rows). Each tuple/row should have five items/columns: a date, an integer for the number of rides, a float for the average distance traveled, a float for the average precipitation amount, and a float the average wind speed. The list of tuples or dataframe should be sorted by total number of rides, descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"busiest_day_weather.sql\"\n",
    "\n",
    "QUERY_4 ='''\n",
    "WITH total AS(\n",
    "    SELECT\n",
    "        trip_miles AS trip_distance,\n",
    "        strftime('%Y-%m-%d',pickup_datetime) AS date\n",
    "    FROM\n",
    "        uber_trips\n",
    "    WHERE\n",
    "        strftime('%Y',pickup_datetime)='2023'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        trip_distance,\n",
    "        strftime('%Y-%m-%d',pickup_datetime) AS date\n",
    "    FROM\n",
    "        yellow_taxi_trips\n",
    "    WHERE\n",
    "        strftime('%Y',pickup_datetime)='2023'\n",
    "),\n",
    "cnt AS(\n",
    "    SELECT\n",
    "        COUNT(*) as ride_cnt,\n",
    "        AVG(trip_distance) AS DailyAverageTripDistance,\n",
    "        date\n",
    "    FROM\n",
    "        total\n",
    "    GROUP BY date\n",
    "),\n",
    "weather AS(\n",
    "    SELECT\n",
    "        DailyAverageWindSpeed,\n",
    "        DailyPrecipitation/24 AS DailyAveragePrecipitation,\n",
    "        strftime('%Y-%m-%d',date) AS date\n",
    "    FROM\n",
    "        weather_daily\n",
    ")\n",
    "    SELECT\n",
    "        cnt.date,\n",
    "        ride_cnt,\n",
    "        DailyAverageTripDistance,\n",
    "        DailyAveragePrecipitation,\n",
    "        DailyAverageWindSpeed\n",
    "    FROM\n",
    "        cnt\n",
    "    LEFT JOIN weather ON cnt.date=weather.date\n",
    "    ORDER BY ride_cnt DESC\n",
    "    LIMIT 10\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_4).fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of these days are weekends,align with our result in query 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 5: How many rides were hired during snow days?\n",
    "Which 10 days in between January 2020 and August 2024 (inclusive) had the most snow, and how many hired trips were made on those days?\n",
    "\n",
    "The result should be a list of 10 tuples. Each tuple should have three items: a date, a float for the total snowfall of that day, and the number of hired trips for that day. The list of tuples should be sorted by snowfall, descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = \"snowest_day_ride.sql\"\n",
    "\n",
    "QUERY_5 ='''\n",
    "WITH snowiest_days AS (\n",
    "    SELECT \n",
    "        date, \n",
    "        DailySnowfall\n",
    "    FROM \n",
    "        weather_daily\n",
    "    WHERE \n",
    "        DailySnowfall > 0\n",
    "    GROUP BY \n",
    "        date\n",
    "    ORDER BY \n",
    "        DailySnowfall DESC\n",
    "    LIMIT 10\n",
    "),total AS \n",
    "(\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d', pickup_datetime) AS date\n",
    "    FROM \n",
    "        yellow_taxi_trips\n",
    "UNION ALL\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d', pickup_datetime) AS date\n",
    "    FROM \n",
    "        uber_trips\n",
    "),cnt AS(\n",
    "    SELECT\n",
    "        COUNT(*) AS ride_cnt,\n",
    "        date\n",
    "    FROM total\n",
    "    GROUP BY date\n",
    ")\n",
    "    SELECT \n",
    "        s.date, \n",
    "        s.DailySnowfall,\n",
    "        c.ride_cnt\n",
    "    FROM \n",
    "        snowiest_days s\n",
    "    LEFT JOIN \n",
    "        cnt c ON c.date = s.date\n",
    "    GROUP BY \n",
    "        s.date\n",
    "    ORDER BY \n",
    "        s.DailySnowfall DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_5).fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 6\n",
    "Tropical Storm Ophelia (September 28-30, 2023) set a new daily rainfall record in NYC with 8.05 inches of rain measured, causing flooding across all of the city. During Ophelia, plus 3 days leading up to it and 3 days after it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive, and what was the sustained wind speed?\n",
    "\n",
    "The result should be a list of roughly 216 tuples/rows (24 hours/day, 9 days), where each tuple is an entry for every single hour of the given date range, even if no rides were taken, no precipitation was measured, or there was no wind. Each tuple should have four items: a string for the date and hour, an int for the number of hired rides in that hour, the float for the total precipitation for that hour, and a float for the average wind speed for that hour. The list of tuples should be ordered by date+hour, ascending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = 'ophelia_impact.sql'\n",
    "QUERY_6 = '''\n",
    "WITH hours_table AS(\n",
    "    SELECT\n",
    "        datetime('2023-09-25 00:00') AS hour\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        datetime(hour,'+1 hour') AS hour\n",
    "    FROM\n",
    "        hours_table\n",
    "    WHERE\n",
    "        hour<datetime('2023-10-03 23:00')\n",
    "),\n",
    "total AS \n",
    "(\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d %H', pickup_datetime) AS hour\n",
    "    FROM \n",
    "        yellow_taxi_trips\n",
    "    WHERE strftime('%Y-%m-%d %H', pickup_datetime) BETWEEN '2023-09-25 00:00' and '2023-10-03 23:59'\n",
    "UNION ALL\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d %H', pickup_datetime) AS hour\n",
    "    FROM \n",
    "        uber_trips\n",
    "    WHERE strftime('%Y-%m-%d %H', pickup_datetime) BETWEEN '2023-09-25 00:00' and '2023-10-03 23:59'\n",
    "),cnt AS(\n",
    "    SELECT\n",
    "        COUNT(*) AS ride_cnt,\n",
    "        hour\n",
    "    FROM total\n",
    "    GROUP BY hour\n",
    "),\n",
    "weather AS(\n",
    "    SELECT\n",
    "        strftime('%Y-%m-%d %H', CAST(Date AS TEXT) || ' ' || printf('%02d', Hour)||':00:00' ) AS hour,\n",
    "\n",
    "        HourlyPrecipitation\n",
    "    FROM\n",
    "        weather_hourly\n",
    "    WHERE strftime('%Y-%m-%d', Date) BETWEEN '2023-09-25' and '2023-10-03'\n",
    "\n",
    ")\n",
    "SELECT\n",
    "    strftime('%Y-%m-%d %H',h.hour),\n",
    "    COALESCE(ride_cnt,0),\n",
    "    COALESCE(HourlyPrecipitation,0)\n",
    "FROM hours_table h\n",
    "LEFT JOIN cnt c ON strftime('%Y-%m-%d %H', h.hour)= c.hour\n",
    "LEFT JOIN weather w ON strftime('%Y-%m-%d %H', h.hour)=w.hour\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    results = conn.execute(QUERY_6).fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_by_hour_taxi_ride_cnt(dataframe):\n",
    "    hour = dataframe['hour']\n",
    "    ride_cnt = dataframe['ride_cnt']\n",
    "    \n",
    "    angles = np.linspace(0,2*np.pi,len(hour),endpoint=False)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(8,8),subplot_kw={'projection':'polar'})\n",
    "    bars = ax.bar(angles,ride_cnt,width=2*np.pi/len(hour),align='center',edgecolor='black')\n",
    "    ax.set_xticks(angles)\n",
    "    ax.set_xticklabels(hour)\n",
    "    \n",
    "    ax.set_theta_direction(-1)  # Clockwise\n",
    "    ax.set_theta_offset(np.pi / 2)  # Start from the top\n",
    "    ax.set_title(\"24-Hour Taxi Ride Popularity\", va='bottom')\n",
    "    \n",
    "    for bar, height in zip(bars, ride_cnt):\n",
    "        bar.set_alpha(0.7)  # Make bars semi-transparent\n",
    "        bar.set_facecolor(plt.cm.viridis(height / max(ride_cnt)))  # Color by height\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_data_for_by_hour_taxi_ride_cnt():\n",
    "    QUERY = \"\"\"\n",
    "        SELECT \n",
    "            strftime('%H', pickup_datetime) AS hour,\n",
    "            COUNT(*) AS ride_cnt\n",
    "        FROM \n",
    "            yellow_taxi_trips\n",
    "        GROUP BY \n",
    "            hour\n",
    "        ORDER BY \n",
    "            ride_cnt DESC;\n",
    "        \"\"\"\n",
    "    with conn:\n",
    "        results = conn.execute(QUERY).fetchall()\n",
    "    return pd.DataFrame(results,columns=['hour','ride_cnt']).sort_values(by='hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_hour_taxi_ride_cnt(get_data_for_by_hour_taxi_ride_cnt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def plot_by_month_hired_avg_distance(dataframe):\n",
    "    groups = dataframe.groupby('month')['distance']\n",
    "    raw = []\n",
    "    for month,group in groups:\n",
    "        distance = group\n",
    "        mean = group.mean()\n",
    "        std = np.std(distance,ddof=1)\n",
    "        n = len(distance)\n",
    "\n",
    "        margin = 1.645*std/np.sqrt(n)\n",
    "        lower = mean - margin\n",
    "        upper = mean + margin\n",
    "\n",
    "        raw.append({'month':month,'mean':mean,'lower':lower,'upper':upper})\n",
    "    df = pd.DataFrame(raw)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(10,6))\n",
    "    line, = ax.plot([],[],label='Average Distance',marker = 'o',color='b')\n",
    "    fill = ax.fill_between([],[],[],color='b',alpha=0.2,label='95% Confidence Interval')\n",
    "\n",
    "    # ax.set_xlim(1,12)\n",
    "    # ax.set_ylim(0,df['upper'].max()+1)\n",
    "    ax.set_title('Monthly Taxi Trip Distance with Confidence Interval')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Average Distance')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "    def update(frame):\n",
    "        cur = df.iloc[:frame+1]\n",
    "        line.set_data(cur['month'],cur['mean'])\n",
    "        global fill\n",
    "        fill.remove()\n",
    "        fill = ax.fill_between(cur['month'],cur['lower'],cur['upper'],color='b',alpha=0.2)\n",
    "        return line,fill\n",
    "    anim = FuncAnimation(fig,update,frames=len(df),interval=500,repeat=False)\n",
    "    return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_data_for_by_month_hired_avg_distance():\n",
    "    QUERY = \"\"\"\n",
    "            SELECT \n",
    "                strftime('%m',pickup_datetime) AS mon,\n",
    "                trip_distance\n",
    "            FROM \n",
    "                yellow_taxi_trips\n",
    "            \n",
    "        UNION ALL\n",
    "\n",
    "            SELECT \n",
    "                strftime('%m',pickup_datetime) AS mon,\n",
    "                trip_miles AS trip_distance\n",
    "                \n",
    "            FROM \n",
    "                uber_trips\n",
    "            \n",
    "        \"\"\"\n",
    "    with conn:\n",
    "        results = conn.execute(QUERY).fetchall()\n",
    "    return pd.DataFrame(results,columns=['month','distance']).sort_values(by='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_month_hired_avg_distance(get_data_for_by_month_hired_avg_distance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Which day of the week is most popular for taking a ride to an NYC-based airport?\n",
    "Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport between January 2020 and August 2024, inclusive. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_day_of_week_frequency_to_airport(dataframe:pd.DataFrame)->None:\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    x = dataframe['day_of_week'].astype(int)\n",
    "    days = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "    plt.xticks(x,days)\n",
    "    plt.bar(x,dataframe['ride_cnt'],label = 'Ride Count')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.ylabel('Ride  count')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_day_of_week_frequency_to_airport()->pd.DataFrame:\n",
    "    QUERY = '''\n",
    "    WITH total AS(\n",
    "        SELECT \n",
    "            strftime('%Y-%m-%d',pickup_datetime) AS date,\n",
    "            dropoff_latitude AS lat,\n",
    "            dropoff_longitude AS lng\n",
    "        FROM \n",
    "            yellow_taxi_trips\n",
    "        WHERE\n",
    "            (dropoff_latitude BETWEEN 40.766 AND 40.790 AND dropoff_longitude BETWEEN -73.890 AND -73.860)\n",
    "            OR\n",
    "            (dropoff_latitude BETWEEN 40.641 AND 40.662 AND dropoff_longitude BETWEEN -73.790 AND -73.750)\n",
    "            OR\n",
    "            (dropoff_latitude BETWEEN 40.689 AND 40.709 AND dropoff_longitude BETWEEN -74.190 AND -74.170)\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT \n",
    "            strftime('%Y-%m-%d',pickup_datetime) AS date,\n",
    "            dropoff_latitude AS lat,\n",
    "            dropoff_longitude AS lng\n",
    "        FROM \n",
    "            uber_trips\n",
    "        WHERE\n",
    "            (dropoff_latitude BETWEEN 40.76 AND 40.77 AND dropoff_longitude BETWEEN -73.88 AND -73.85)\n",
    "            OR\n",
    "            (dropoff_latitude BETWEEN 40.62 AND 40.66 AND dropoff_longitude BETWEEN -73.82 AND -73.74)\n",
    "            OR\n",
    "            (dropoff_latitude BETWEEN 40.67 AND 40.70 AND dropoff_longitude BETWEEN -74.19 AND -74.15)\n",
    "        )\n",
    "    SELECT\n",
    "        strftime('%w',date) AS day_of_week,\n",
    "        COUNT(*) AS ride_cnt\n",
    "    FROM total\n",
    "    GROUP BY strftime('%w',date)\n",
    "'''\n",
    "    with conn:\n",
    "        results = conn.execute(QUERY).fetchall()\n",
    "    return pd.DataFrame(results,columns=['day_of_week','ride_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = get_data_for_day_of_week_frequency_to_airport()\n",
    "plot_day_of_week_frequency_to_airport(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people might start the travel at the end of the weekday(Thu,Fri),and people who travel to NY might go home at Sunday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization 4: How much do hired rides earn in total fares monthly?\n",
    "Create an appropriate visualization that compares the monthly earned total fares between January 2020 through August 2024 (inclusive) for Yellow Taxis and Ubers each. Additionally, separate out fares, surcharges, taxes, and tolls.\n",
    "\n",
    "Note: Total fare = base fare + all surcharges + taxes + tolls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_fare(dataframe:pd.DataFrame)->None:\n",
    "    month = pd.to_datetime(dataframe['month']).apply(lambda x:x.strftime('%Y-%m'))\n",
    "    uber = dataframe[['uber_base_fare','uber_all_surcharges','uber_taxes','uber_tolls','uber_total']]\n",
    "    taxi = dataframe[['taxi_base_fare','taxi_all_surcharges','taxi_taxes','taxi_tolls','taxi_total']]\n",
    "    components = ['total','base_fare','all_surcharges','taxes','tolls']\n",
    "    x = np.arange(len(month))\n",
    "    width = 0.3\n",
    "    fig,ax = plt.subplots(5,1,figsize=(14,16))\n",
    "    for i,component in enumerate(components):\n",
    "        ax[i].bar(x-width/2,taxi[f'taxi_{component}'],width,label='taxi')\n",
    "        ax[i].bar(x+width/2,uber[f'uber_{component}'],width,label='uber')\n",
    "\n",
    "        ax[i].set_title(f'Monthly {component} comparation')\n",
    "        ax[i].set_xlabel('Month')\n",
    "        ax[i].set_ylabel(f'{component} Amount')\n",
    "\n",
    "        tick_interval = 4\n",
    "        xticks_indices = range(0,len(month),tick_interval)\n",
    "        xtick_labels = month[xticks_indices]\n",
    "\n",
    "        ax[i].set_xticks(xticks_indices)\n",
    "        ax[i].set_xticklabels(xtick_labels)\n",
    "        ax[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_monthly_fare()->pd.DataFrame:\n",
    "    QUERY = '''\n",
    "    WITH uber AS(\n",
    "    SELECT\n",
    "        SUM(COALESCE(base_passenger_fare,0)) AS uber_base_fare,\n",
    "        SUM(COALESCE(congestion_surcharge,0))+SUM(COALESCE(airport_fee,0))+SUM(COALESCE(Black_Car_Fund,0)) AS uber_all_surcharges,\n",
    "        SUM(COALESCE(sales_tax,0)) AS uber_taxes,\n",
    "        SUM(COALESCE(tolls,0)) as uber_tolls,\n",
    "        strftime('%Y-%m',pickup_datetime) AS uber_month\n",
    "    FROM uber_trips\n",
    "    GROUP BY strftime('%Y-%m',pickup_datetime)),\n",
    "    taxi AS(\n",
    "    SELECT \n",
    "        SUM(COALESCE(fare_amount,0)) AS taxi_base_fare,\n",
    "        SUM(COALESCE(Miscellaneous_Extras,0))+SUM(COALESCE(improvement_surcharge,0))+SUM(COALESCE(congestion_surcharge,0))+SUM(COALESCE(airport_fee,0)) AS taxi_all_surcharges,\n",
    "        SUM(COALESCE(mta_tax,0)) AS taxi_taxes,\n",
    "        SUM(COALESCE(tolls_amount,0)) AS taxi_tolls,\n",
    "        strftime('%Y-%m',pickup_datetime) AS taxi_month\n",
    "    FROM yellow_taxi_trips\n",
    "    GROUP BY strftime('%Y-%m',pickup_datetime))\n",
    "    SELECT\n",
    "        uber_month,uber_base_fare,uber_all_surcharges,uber_taxes,uber_tolls,\n",
    "        taxi_base_fare,taxi_all_surcharges,taxi_taxes,taxi_tolls,\n",
    "        uber_base_fare+uber_all_surcharges+uber_taxes+uber_tolls AS uber_total,\n",
    "        taxi_base_fare+taxi_all_surcharges+taxi_taxes+taxi_tolls AS taxi_total\n",
    "    FROM uber\n",
    "    JOIN taxi\n",
    "    ON uber_month=taxi_month\n",
    "'''\n",
    "    with conn:\n",
    "        results = conn.execute(QUERY).fetchall()\n",
    "    return pd.DataFrame(results,columns=['month','uber_base_fare','uber_all_surcharges','uber_taxes','uber_tolls',\n",
    "        'taxi_base_fare','taxi_all_surcharges','taxi_taxes','taxi_tolls','uber_total','taxi_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = get_data_for_monthly_fare()\n",
    "plot_monthly_fare(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization 5: Does precipitation or distance traveled affect the amount of tip?\n",
    "For the year 2022-2023, create 4 scatter plots, each one comparing amount of tip versus: \n",
    "distance for Yellow Taxi rides,\n",
    "distance for Uber rides,\n",
    "precipitation for Yellow Taxi rides, \n",
    "precipitation for Uber rides.\n",
    "\n",
    "You may remove any outliers how you see fit.\n",
    "\n",
    "If using matplotlib, then create a single figure with 2x2 subplots (example). If using another visualization library, try to accomplish something similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "    return df[(df[col]>=lower_bound)&(df[col]<=upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tip_factors(uber,taxi,weather)->None:\n",
    "    uber = uber[uber['tips']<=50]\n",
    "    taxi = taxi[taxi['tips']<=50]\n",
    "    uber_weather = pd.merge(uber,weather,on='hour',how='left')\n",
    "    taxi_weather = pd.merge(taxi,weather,on='hour',how='left')\n",
    "    uber_weather_distance = remove_outliers(uber_weather,'distance')\n",
    "    taxi_weather_distance = remove_outliers(taxi_weather,'distance')\n",
    "\n",
    "    fig,ax = plt.subplots(2,2,figsize=(12,10))\n",
    "    ax[0,0].scatter(taxi_weather_distance['distance'],taxi_weather_distance['tips'],alpha=0.1)\n",
    "    ax[0,0].set_title('taxi: distance VS tips')\n",
    "    ax[0,0].set_xlabel('distance')\n",
    "    ax[0,0].set_ylabel('tips')\n",
    "\n",
    "    ax[0,1].scatter(uber_weather_distance['distance'],uber_weather_distance['tips'],alpha=0.1)\n",
    "    ax[0,1].set_title('uber: distance VS tips')\n",
    "    ax[0,1].set_xlabel('distance')\n",
    "    ax[0,1].set_ylabel('tips')\n",
    "\n",
    "    ax[1,0].scatter(taxi_weather['HourlyPrecipitation'],taxi_weather['tips'],alpha=0.1)\n",
    "    ax[1,0].set_title('taxi: precipitation VS tips')\n",
    "    ax[1,0].set_xlabel('precipitation')\n",
    "    ax[1,0].set_ylabel('tips')\n",
    "\n",
    "    ax[1,1].scatter(uber_weather['HourlyPrecipitation'],uber_weather['tips'],alpha=0.1)\n",
    "    ax[1,1].set_title('uber: precipitation VS tips')\n",
    "    ax[1,1].set_xlabel('precipitation')\n",
    "    ax[1,1].set_ylabel('tips')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_tip_factors():\n",
    "    UBER_QUERY = '''\n",
    "    SELECT\n",
    "        strftime('%Y-%m-%d %H',pickup_datetime) AS hour_time,\n",
    "        tips,\n",
    "        trip_miles\n",
    "    FROM uber_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) BETWEEN '2022' AND '2023'\n",
    "    '''\n",
    "    TAXI_QUERY = '''\n",
    "    SELECT\n",
    "        strftime('%Y-%m-%d %H',pickup_datetime) AS hour_time,\n",
    "        tip_amount,\n",
    "        trip_distance\n",
    "    FROM yellow_taxi_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) BETWEEN '2022' AND '2023'\n",
    "'''\n",
    "    WEATHER_QUERY = '''\n",
    "    SELECT \n",
    "        strftime('%Y-%m-%d %H',CAST(Date AS TEXT) || ' ' || printf('%02d', Hour)||':00:00') AS hour_time,\n",
    "        HourlyPrecipitation\n",
    "    FROM weather_hourly\n",
    "    WHERE strftime('%Y',Date) BETWEEN '2022' AND '2023'\n",
    "'''\n",
    "    with conn:\n",
    "        uber = conn.execute(UBER_QUERY).fetchall()\n",
    "        taxi = conn.execute(TAXI_QUERY).fetchall()\n",
    "        weather = conn.execute(WEATHER_QUERY).fetchall()\n",
    "    return  [pd.DataFrame(uber,columns=['hour','tips','distance']),pd.DataFrame(taxi,columns=['hour','tips','distance']),pd.DataFrame(weather,columns=['hour','HourlyPrecipitation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber,taxi,weather = get_data_for_tip_factors()\n",
    "plot_tip_factors(uber,taxi,weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a heatmap of all hired trips in 2020 over a map of the area. Consider using Folium, geopandas, KeplerGL, geoplot, or another library that helps generate geospatial visualizations.\n",
    "\n",
    "Depending on the library you use, the visualization may not render when viewing on GitHub (after you’ve pushed your code). If that’s the case, please include a screenshot in your repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dataframe:pd.DataFrame)->None:\n",
    "    pick_counts = dataframe.groupby(['pick_lat','pick_lng']).size().reset_index(name='counts')\n",
    "    pick_data = pick_counts[['pick_lat','pick_lng','counts']].values\n",
    "    drop_counts = dataframe.groupby(['drop_lat','drop_lng']).size().reset_index(name='counts')\n",
    "    drop_data = drop_counts[['drop_lat','drop_lng','counts']].values\n",
    "    from folium.plugins import HeatMap\n",
    "    import folium\n",
    "    pick_m = folium.Map(location=[dataframe['pick_lat'].mean(),dataframe['pick_lng'].mean()],zomm_start=12)\n",
    "    drop_m = folium.Map(location = [dataframe['drop_lat'].mean(),dataframe['drop_lng'].mean()],zoom_start=12)\n",
    "\n",
    "    HeatMap(pick_data,radius=15,blur=10,min_opacity=0.2).add_to(pick_m)\n",
    "    HeatMap(drop_data,radius=15,blur=10,min_opacity=0.2).add_to(drop_m)\n",
    "    display(pick_m)\n",
    "    display(drop_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_heatmap():\n",
    "    QUERY = '''\n",
    "    SELECT\n",
    "        pickup_latitude AS pick_lat,\n",
    "        pickup_longitude AS pick_lng,\n",
    "        dropoff_latitude AS drop_lat,\n",
    "        dropoff_longitude AS drop_lng\n",
    "    FROM uber_trips\n",
    "    WHERE strftime('%Y',pickup_datetime)='2020'\n",
    "    UNION\n",
    "    SELECT\n",
    "        pickup_latitude AS pick_lat,\n",
    "        pickup_longitude AS pick_lng,\n",
    "        dropoff_latitude AS drop_lat,\n",
    "        dropoff_longitude AS drop_lng\n",
    "    FROM yellow_taxi_trips\n",
    "    WHERE strftime('%Y',pickup_datetime)='2020'\n",
    "    '''\n",
    "    with conn:\n",
    "        results = conn.execute(QUERY).fetchall()\n",
    "    return pd.DataFrame(results,columns=['pick_lat','pick_lng','drop_lat','drop_lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = get_data_for_heatmap()\n",
    "plot_heatmap(dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
